{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "molembed_path = \"/home/wbm001/deeplpi/data/davis/mol.csv\"\n",
    "seqembed_path = \"/home/wbm001/deeplpi/data/davis/seq_6165.csv\"\n",
    "train_path = \"/home/wbm001/deeplpi/data/davis/trainset.csv\"\n",
    "test_path = \"/home/wbm001/deeplpi/data/davis/testset.csv\"\n",
    "tensorboard_path = \"/home/wbm001/deeplpi/DeepLPI/output/tensorboard/\"\n",
    "data_path = \"/home/wbm001/deeplpi/DeepLPI/output/\"\n",
    "\n",
    "RAMDOMSEED = 11\n",
    "CLASSIFYBOUND = -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seqembed = pd.read_csv(seqembed_path)\n",
    "molembed = pd.read_csv(molembed_path)\n",
    "train = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6155</th>\n",
       "      <th>6156</th>\n",
       "      <th>6157</th>\n",
       "      <th>6158</th>\n",
       "      <th>6159</th>\n",
       "      <th>6160</th>\n",
       "      <th>6161</th>\n",
       "      <th>6162</th>\n",
       "      <th>6163</th>\n",
       "      <th>6164</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.444723</td>\n",
       "      <td>-81.539060</td>\n",
       "      <td>9.510525</td>\n",
       "      <td>68.299870</td>\n",
       "      <td>13.309365</td>\n",
       "      <td>-78.865980</td>\n",
       "      <td>-64.683740</td>\n",
       "      <td>3.850614</td>\n",
       "      <td>324.210820</td>\n",
       "      <td>27.800323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.476349</td>\n",
       "      <td>0.263945</td>\n",
       "      <td>16.897220</td>\n",
       "      <td>43.199890</td>\n",
       "      <td>44.520400</td>\n",
       "      <td>-98.090454</td>\n",
       "      <td>-2.703444</td>\n",
       "      <td>43.146687</td>\n",
       "      <td>405.128970</td>\n",
       "      <td>71.851790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.476349</td>\n",
       "      <td>0.263945</td>\n",
       "      <td>16.897220</td>\n",
       "      <td>43.199890</td>\n",
       "      <td>44.520400</td>\n",
       "      <td>-98.090454</td>\n",
       "      <td>-2.703444</td>\n",
       "      <td>43.146687</td>\n",
       "      <td>405.128970</td>\n",
       "      <td>71.851790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.476349</td>\n",
       "      <td>0.263945</td>\n",
       "      <td>16.897220</td>\n",
       "      <td>43.199890</td>\n",
       "      <td>44.520400</td>\n",
       "      <td>-98.090454</td>\n",
       "      <td>-2.703444</td>\n",
       "      <td>43.146687</td>\n",
       "      <td>405.128970</td>\n",
       "      <td>71.851790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.476349</td>\n",
       "      <td>0.263945</td>\n",
       "      <td>16.897220</td>\n",
       "      <td>43.199890</td>\n",
       "      <td>44.520400</td>\n",
       "      <td>-98.090454</td>\n",
       "      <td>-2.703444</td>\n",
       "      <td>43.146687</td>\n",
       "      <td>405.128970</td>\n",
       "      <td>71.851790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.264088</td>\n",
       "      <td>-35.136560</td>\n",
       "      <td>14.843793</td>\n",
       "      <td>22.488441</td>\n",
       "      <td>44.845030</td>\n",
       "      <td>-19.335789</td>\n",
       "      <td>24.064278</td>\n",
       "      <td>2.771445</td>\n",
       "      <td>263.130600</td>\n",
       "      <td>6.966480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.917180</td>\n",
       "      <td>-33.736206</td>\n",
       "      <td>5.455640</td>\n",
       "      <td>12.658602</td>\n",
       "      <td>35.118217</td>\n",
       "      <td>-19.611599</td>\n",
       "      <td>29.297453</td>\n",
       "      <td>19.599400</td>\n",
       "      <td>102.706535</td>\n",
       "      <td>0.360979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>50.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.822379</td>\n",
       "      <td>-167.640260</td>\n",
       "      <td>-3.142028</td>\n",
       "      <td>25.450462</td>\n",
       "      <td>15.813288</td>\n",
       "      <td>-122.869995</td>\n",
       "      <td>-24.707890</td>\n",
       "      <td>-169.986330</td>\n",
       "      <td>448.487550</td>\n",
       "      <td>249.686800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>36.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.063804</td>\n",
       "      <td>-107.607666</td>\n",
       "      <td>12.299452</td>\n",
       "      <td>40.532520</td>\n",
       "      <td>23.953854</td>\n",
       "      <td>-62.065600</td>\n",
       "      <td>22.421020</td>\n",
       "      <td>-53.265434</td>\n",
       "      <td>123.143160</td>\n",
       "      <td>36.953835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>54.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.201620</td>\n",
       "      <td>-60.851610</td>\n",
       "      <td>12.529304</td>\n",
       "      <td>9.014238</td>\n",
       "      <td>44.140860</td>\n",
       "      <td>-49.113544</td>\n",
       "      <td>40.320175</td>\n",
       "      <td>6.163600</td>\n",
       "      <td>298.501040</td>\n",
       "      <td>1.640686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 6165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4      5      6     7     8     9  ...  \\\n",
       "id                                                                 ...   \n",
       "1    79.0  32.0  33.0  45.0  13.0  112.0   43.0  65.0  15.0  40.0  ...   \n",
       "2    99.0  68.0  42.0  43.0  12.0   36.0   91.0  94.0  28.0  34.0  ...   \n",
       "3    99.0  68.0  42.0  43.0  12.0   36.0   91.0  94.0  28.0  34.0  ...   \n",
       "4    99.0  68.0  42.0  43.0  12.0   36.0   91.0  94.0  28.0  34.0  ...   \n",
       "5    99.0  68.0  42.0  43.0  12.0   36.0   91.0  94.0  28.0  34.0  ...   \n",
       "..    ...   ...   ...   ...   ...    ...    ...   ...   ...   ...  ...   \n",
       "438  37.0  26.0  19.0  24.0   9.0   19.0   42.0  45.0   8.0  28.0  ...   \n",
       "439  23.0  22.0  10.0  23.0   4.0   15.0   40.0  29.0  16.0  28.0  ...   \n",
       "440  50.0  61.0  75.0  58.0  27.0   62.0  120.0  56.0  45.0  77.0  ...   \n",
       "441  36.0  47.0  33.0  43.0  11.0   33.0   59.0  46.0  25.0  42.0  ...   \n",
       "442  54.0  37.0  14.0  31.0  17.0   23.0   46.0  42.0  16.0  24.0  ...   \n",
       "\n",
       "          6155        6156       6157       6158       6159        6160  \\\n",
       "id                                                                        \n",
       "1     6.444723  -81.539060   9.510525  68.299870  13.309365  -78.865980   \n",
       "2   -22.476349    0.263945  16.897220  43.199890  44.520400  -98.090454   \n",
       "3   -22.476349    0.263945  16.897220  43.199890  44.520400  -98.090454   \n",
       "4   -22.476349    0.263945  16.897220  43.199890  44.520400  -98.090454   \n",
       "5   -22.476349    0.263945  16.897220  43.199890  44.520400  -98.090454   \n",
       "..         ...         ...        ...        ...        ...         ...   \n",
       "438 -11.264088  -35.136560  14.843793  22.488441  44.845030  -19.335789   \n",
       "439  -5.917180  -33.736206   5.455640  12.658602  35.118217  -19.611599   \n",
       "440  -3.822379 -167.640260  -3.142028  25.450462  15.813288 -122.869995   \n",
       "441  -6.063804 -107.607666  12.299452  40.532520  23.953854  -62.065600   \n",
       "442 -11.201620  -60.851610  12.529304   9.014238  44.140860  -49.113544   \n",
       "\n",
       "          6161        6162        6163        6164  \n",
       "id                                                  \n",
       "1   -64.683740    3.850614  324.210820   27.800323  \n",
       "2    -2.703444   43.146687  405.128970   71.851790  \n",
       "3    -2.703444   43.146687  405.128970   71.851790  \n",
       "4    -2.703444   43.146687  405.128970   71.851790  \n",
       "5    -2.703444   43.146687  405.128970   71.851790  \n",
       "..         ...         ...         ...         ...  \n",
       "438  24.064278    2.771445  263.130600    6.966480  \n",
       "439  29.297453   19.599400  102.706535    0.360979  \n",
       "440 -24.707890 -169.986330  448.487550  249.686800  \n",
       "441  22.421020  -53.265434  123.143160   36.953835  \n",
       "442  40.320175    6.163600  298.501040    1.640686  \n",
       "\n",
       "[442 rows x 6165 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqembed=seqembed.set_index(\"id\").iloc[:,1:]\n",
    "seqembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829822</td>\n",
       "      <td>-2.898041</td>\n",
       "      <td>-4.649384</td>\n",
       "      <td>9.345411</td>\n",
       "      <td>2.024538</td>\n",
       "      <td>0.013855</td>\n",
       "      <td>-11.944915</td>\n",
       "      <td>-1.597213</td>\n",
       "      <td>9.198922</td>\n",
       "      <td>1.238771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.517237</td>\n",
       "      <td>10.861519</td>\n",
       "      <td>12.824284</td>\n",
       "      <td>0.950313</td>\n",
       "      <td>-5.809847</td>\n",
       "      <td>-1.840369</td>\n",
       "      <td>-2.391321</td>\n",
       "      <td>-3.924023</td>\n",
       "      <td>-12.244526</td>\n",
       "      <td>-2.074422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.854995</td>\n",
       "      <td>-7.414621</td>\n",
       "      <td>-3.060668</td>\n",
       "      <td>11.007050</td>\n",
       "      <td>2.219870</td>\n",
       "      <td>0.760429</td>\n",
       "      <td>-18.984646</td>\n",
       "      <td>-3.411269</td>\n",
       "      <td>9.880671</td>\n",
       "      <td>4.160527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497948</td>\n",
       "      <td>14.079114</td>\n",
       "      <td>15.602748</td>\n",
       "      <td>-4.369925</td>\n",
       "      <td>-11.898266</td>\n",
       "      <td>-7.236622</td>\n",
       "      <td>-8.713088</td>\n",
       "      <td>-6.302337</td>\n",
       "      <td>-17.494871</td>\n",
       "      <td>-5.129542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.566384</td>\n",
       "      <td>-9.376981</td>\n",
       "      <td>-4.701758</td>\n",
       "      <td>9.937780</td>\n",
       "      <td>-1.505315</td>\n",
       "      <td>-0.724521</td>\n",
       "      <td>-18.245934</td>\n",
       "      <td>-1.676159</td>\n",
       "      <td>13.776966</td>\n",
       "      <td>6.455488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471755</td>\n",
       "      <td>14.923586</td>\n",
       "      <td>15.908692</td>\n",
       "      <td>-0.827523</td>\n",
       "      <td>-12.513768</td>\n",
       "      <td>-2.727590</td>\n",
       "      <td>-7.129415</td>\n",
       "      <td>-7.387351</td>\n",
       "      <td>-17.518423</td>\n",
       "      <td>-3.197533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.489536</td>\n",
       "      <td>-4.903131</td>\n",
       "      <td>-2.508207</td>\n",
       "      <td>1.998400</td>\n",
       "      <td>-1.843629</td>\n",
       "      <td>-1.459605</td>\n",
       "      <td>-7.680352</td>\n",
       "      <td>-0.618287</td>\n",
       "      <td>7.322994</td>\n",
       "      <td>4.992087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.614348</td>\n",
       "      <td>12.279282</td>\n",
       "      <td>9.248433</td>\n",
       "      <td>-1.361801</td>\n",
       "      <td>-7.393184</td>\n",
       "      <td>-3.451234</td>\n",
       "      <td>-6.638332</td>\n",
       "      <td>-7.178052</td>\n",
       "      <td>-10.681926</td>\n",
       "      <td>-1.355820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.618258</td>\n",
       "      <td>-6.360738</td>\n",
       "      <td>-4.437974</td>\n",
       "      <td>7.045229</td>\n",
       "      <td>1.035484</td>\n",
       "      <td>1.088520</td>\n",
       "      <td>-14.490010</td>\n",
       "      <td>1.202196</td>\n",
       "      <td>8.513885</td>\n",
       "      <td>5.116467</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.473603</td>\n",
       "      <td>12.468008</td>\n",
       "      <td>13.643344</td>\n",
       "      <td>-0.530653</td>\n",
       "      <td>-12.833990</td>\n",
       "      <td>-8.074208</td>\n",
       "      <td>-10.613939</td>\n",
       "      <td>-7.116803</td>\n",
       "      <td>-15.068073</td>\n",
       "      <td>-3.534183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.713710</td>\n",
       "      <td>-7.050503</td>\n",
       "      <td>-2.884163</td>\n",
       "      <td>8.847737</td>\n",
       "      <td>0.230745</td>\n",
       "      <td>-1.685087</td>\n",
       "      <td>-15.651673</td>\n",
       "      <td>-0.220775</td>\n",
       "      <td>5.998096</td>\n",
       "      <td>3.044026</td>\n",
       "      <td>...</td>\n",
       "      <td>1.265174</td>\n",
       "      <td>12.614569</td>\n",
       "      <td>11.444197</td>\n",
       "      <td>-3.224770</td>\n",
       "      <td>-12.173791</td>\n",
       "      <td>-3.535356</td>\n",
       "      <td>-9.283658</td>\n",
       "      <td>-5.514596</td>\n",
       "      <td>-14.788419</td>\n",
       "      <td>-1.109141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5.500631</td>\n",
       "      <td>-4.493319</td>\n",
       "      <td>-3.386489</td>\n",
       "      <td>11.239219</td>\n",
       "      <td>-4.005799</td>\n",
       "      <td>1.801572</td>\n",
       "      <td>-11.644670</td>\n",
       "      <td>0.120213</td>\n",
       "      <td>8.608429</td>\n",
       "      <td>6.391554</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.980491</td>\n",
       "      <td>9.735351</td>\n",
       "      <td>14.402610</td>\n",
       "      <td>-1.712012</td>\n",
       "      <td>-7.102248</td>\n",
       "      <td>-2.911482</td>\n",
       "      <td>-4.938530</td>\n",
       "      <td>-3.572655</td>\n",
       "      <td>-12.192183</td>\n",
       "      <td>-2.234143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4.367358</td>\n",
       "      <td>-5.849614</td>\n",
       "      <td>-3.968088</td>\n",
       "      <td>10.454214</td>\n",
       "      <td>-0.462240</td>\n",
       "      <td>0.095354</td>\n",
       "      <td>-12.705883</td>\n",
       "      <td>0.588735</td>\n",
       "      <td>5.598296</td>\n",
       "      <td>3.270374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588564</td>\n",
       "      <td>13.720288</td>\n",
       "      <td>10.452909</td>\n",
       "      <td>-3.104895</td>\n",
       "      <td>-10.269055</td>\n",
       "      <td>-6.404325</td>\n",
       "      <td>-8.956797</td>\n",
       "      <td>-6.961347</td>\n",
       "      <td>-13.727525</td>\n",
       "      <td>-2.653022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3.484026</td>\n",
       "      <td>-4.835081</td>\n",
       "      <td>-4.481750</td>\n",
       "      <td>6.492329</td>\n",
       "      <td>0.192186</td>\n",
       "      <td>-2.316221</td>\n",
       "      <td>-16.802685</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>11.247752</td>\n",
       "      <td>5.589071</td>\n",
       "      <td>...</td>\n",
       "      <td>1.661140</td>\n",
       "      <td>17.999266</td>\n",
       "      <td>14.120013</td>\n",
       "      <td>1.387156</td>\n",
       "      <td>-14.345608</td>\n",
       "      <td>-5.016685</td>\n",
       "      <td>-8.465631</td>\n",
       "      <td>-6.975369</td>\n",
       "      <td>-17.555494</td>\n",
       "      <td>-4.073402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2.413647</td>\n",
       "      <td>-3.996776</td>\n",
       "      <td>-2.739635</td>\n",
       "      <td>10.940674</td>\n",
       "      <td>-0.844881</td>\n",
       "      <td>0.973736</td>\n",
       "      <td>-10.503655</td>\n",
       "      <td>-0.877855</td>\n",
       "      <td>9.324513</td>\n",
       "      <td>4.262482</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.974042</td>\n",
       "      <td>10.594699</td>\n",
       "      <td>13.612504</td>\n",
       "      <td>-1.413983</td>\n",
       "      <td>-4.425255</td>\n",
       "      <td>-0.653628</td>\n",
       "      <td>-3.176648</td>\n",
       "      <td>-1.704090</td>\n",
       "      <td>-9.163329</td>\n",
       "      <td>-0.874198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2          3         4         5          6  \\\n",
       "id                                                                           \n",
       "1   0.829822 -2.898041 -4.649384   9.345411  2.024538  0.013855 -11.944915   \n",
       "2   2.854995 -7.414621 -3.060668  11.007050  2.219870  0.760429 -18.984646   \n",
       "3   6.566384 -9.376981 -4.701758   9.937780 -1.505315 -0.724521 -18.245934   \n",
       "4   3.489536 -4.903131 -2.508207   1.998400 -1.843629 -1.459605  -7.680352   \n",
       "5   4.618258 -6.360738 -4.437974   7.045229  1.035484  1.088520 -14.490010   \n",
       "..       ...       ...       ...        ...       ...       ...        ...   \n",
       "64  5.713710 -7.050503 -2.884163   8.847737  0.230745 -1.685087 -15.651673   \n",
       "65  5.500631 -4.493319 -3.386489  11.239219 -4.005799  1.801572 -11.644670   \n",
       "66  4.367358 -5.849614 -3.968088  10.454214 -0.462240  0.095354 -12.705883   \n",
       "67  3.484026 -4.835081 -4.481750   6.492329  0.192186 -2.316221 -16.802685   \n",
       "68  2.413647 -3.996776 -2.739635  10.940674 -0.844881  0.973736 -10.503655   \n",
       "\n",
       "           7          8         9  ...       290        291        292  \\\n",
       "id                                 ...                                   \n",
       "1  -1.597213   9.198922  1.238771  ... -0.517237  10.861519  12.824284   \n",
       "2  -3.411269   9.880671  4.160527  ... -0.497948  14.079114  15.602748   \n",
       "3  -1.676159  13.776966  6.455488  ...  0.471755  14.923586  15.908692   \n",
       "4  -0.618287   7.322994  4.992087  ... -0.614348  12.279282   9.248433   \n",
       "5   1.202196   8.513885  5.116467  ... -1.473603  12.468008  13.643344   \n",
       "..       ...        ...       ...  ...       ...        ...        ...   \n",
       "64 -0.220775   5.998096  3.044026  ...  1.265174  12.614569  11.444197   \n",
       "65  0.120213   8.608429  6.391554  ... -3.980491   9.735351  14.402610   \n",
       "66  0.588735   5.598296  3.270374  ...  0.588564  13.720288  10.452909   \n",
       "67  0.016247  11.247752  5.589071  ...  1.661140  17.999266  14.120013   \n",
       "68 -0.877855   9.324513  4.262482  ... -2.974042  10.594699  13.612504   \n",
       "\n",
       "         293        294       295        296       297        298       299  \n",
       "id                                                                           \n",
       "1   0.950313  -5.809847 -1.840369  -2.391321 -3.924023 -12.244526 -2.074422  \n",
       "2  -4.369925 -11.898266 -7.236622  -8.713088 -6.302337 -17.494871 -5.129542  \n",
       "3  -0.827523 -12.513768 -2.727590  -7.129415 -7.387351 -17.518423 -3.197533  \n",
       "4  -1.361801  -7.393184 -3.451234  -6.638332 -7.178052 -10.681926 -1.355820  \n",
       "5  -0.530653 -12.833990 -8.074208 -10.613939 -7.116803 -15.068073 -3.534183  \n",
       "..       ...        ...       ...        ...       ...        ...       ...  \n",
       "64 -3.224770 -12.173791 -3.535356  -9.283658 -5.514596 -14.788419 -1.109141  \n",
       "65 -1.712012  -7.102248 -2.911482  -4.938530 -3.572655 -12.192183 -2.234143  \n",
       "66 -3.104895 -10.269055 -6.404325  -8.956797 -6.961347 -13.727525 -2.653022  \n",
       "67  1.387156 -14.345608 -5.016685  -8.465631 -6.975369 -17.555494 -4.073402  \n",
       "68 -1.413983  -4.425255 -0.653628  -3.176648 -1.704090  -9.163329 -0.874198  \n",
       "\n",
       "[68 rows x 300 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molembed = molembed.set_index(\"id\").iloc[:,1:]\n",
    "molembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Davis_Fake_ID</th>\n",
       "      <th>mol</th>\n",
       "      <th>seq</th>\n",
       "      <th>Kd (nM)</th>\n",
       "      <th>pKd (nM)</th>\n",
       "      <th>Binding Strong</th>\n",
       "      <th>Binding Weak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70270439</td>\n",
       "      <td>27</td>\n",
       "      <td>439</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70420421</td>\n",
       "      <td>42</td>\n",
       "      <td>421</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70120144</td>\n",
       "      <td>12</td>\n",
       "      <td>144</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70490134</td>\n",
       "      <td>49</td>\n",
       "      <td>134</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70110427</td>\n",
       "      <td>11</td>\n",
       "      <td>427</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-1.78533</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19710</th>\n",
       "      <td>70330365</td>\n",
       "      <td>33</td>\n",
       "      <td>365</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19711</th>\n",
       "      <td>7061041</td>\n",
       "      <td>61</td>\n",
       "      <td>41</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19712</th>\n",
       "      <td>70430253</td>\n",
       "      <td>43</td>\n",
       "      <td>253</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19713</th>\n",
       "      <td>70660274</td>\n",
       "      <td>66</td>\n",
       "      <td>274</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19714</th>\n",
       "      <td>7016065</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19715 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Davis_Fake_ID  mol  seq  Kd (nM)  pKd (nM)  Binding Strong  \\\n",
       "0           70270439   27  439  10000.0  -4.00000               0   \n",
       "1           70420421   42  421  10000.0  -4.00000               0   \n",
       "2           70120144   12  144  10000.0  -4.00000               0   \n",
       "3           70490134   49  134  10000.0  -4.00000               0   \n",
       "4           70110427   11  427     61.0  -1.78533               1   \n",
       "...              ...  ...  ...      ...       ...             ...   \n",
       "19710       70330365   33  365  10000.0  -4.00000               0   \n",
       "19711        7061041   61   41  10000.0  -4.00000               0   \n",
       "19712       70430253   43  253  10000.0  -4.00000               0   \n",
       "19713       70660274   66  274  10000.0  -4.00000               0   \n",
       "19714        7016065   16   65  10000.0  -4.00000               0   \n",
       "\n",
       "       Binding Weak  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 1  \n",
       "...             ...  \n",
       "19710             0  \n",
       "19711             0  \n",
       "19712             0  \n",
       "19713             0  \n",
       "19714             0  \n",
       "\n",
       "[19715 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader,TensorDataset,SequentialSampler,RandomSampler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(train, test_size=1000, random_state=RAMDOMSEED)\n",
    "\n",
    "# train\n",
    "train_seq = tensor(np.array(seqembed.loc[train[\"seq\"]])).to(torch.float32)\n",
    "train_mol = tensor(np.array(molembed.loc[train[\"mol\"]])).to(torch.float32)\n",
    "train_classify = tensor(np.array(train[\"pKd (nM)\"].map(lambda x : 1 if x > CLASSIFYBOUND else 0))).to(torch.float32)\n",
    "\n",
    "trainDataset = TensorDataset(train_mol,train_seq,train_classify)\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=256)\n",
    "\n",
    "#val\n",
    "val_seq = tensor(np.array(seqembed.loc[val[\"seq\"]])).to(torch.float32)\n",
    "val_mol = tensor(np.array(molembed.loc[val[\"mol\"]])).to(torch.float32)\n",
    "val_classify = tensor(np.array(val[\"pKd (nM)\"].map(lambda x : 1 if x > CLASSIFYBOUND else 0))).to(torch.float32)\n",
    "\n",
    "# valDataset = TensorDataset(val_mol,val_seq,val_classify)\n",
    "# valDataLoader = DataLoader(valDataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_conv1=False, strides=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.process = nn.Sequential (\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=strides, padding=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_channels)\n",
    "        )\n",
    "        \n",
    "        if use_conv1:\n",
    "            self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv1 = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        left = self.process(x)\n",
    "        right = x if self.conv1 is None else self.conv1(x)\n",
    "        \n",
    "        return F.relu(left + right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnnModule(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, hidden_channel=32, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.head = nn.Sequential (\n",
    "            nn.Conv1d(in_channel, hidden_channel, 7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm1d(hidden_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        self.cnn = nn.Sequential (\n",
    "            resBlock(hidden_channel, out_channel, use_conv1=True, strides=1),\n",
    "            resBlock(out_channel, out_channel, strides=1),\n",
    "            resBlock(out_channel, out_channel, strides=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.head(x)\n",
    "        x = self.cnn(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLPI(nn.Module):\n",
    "    def __init__(self, molshape, seqshape, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.molshape = molshape\n",
    "        self.seqshape = seqshape\n",
    "\n",
    "        self.molcnn = cnnModule(1,16)\n",
    "        self.seqcnn = cnnModule(1,16)\n",
    "        \n",
    "        self.pool = nn.AvgPool1d(5, stride = 3)\n",
    "        self.lstm = nn.LSTM(16, 16, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.mlp = nn.Sequential (\n",
    "            nn.Linear(round(((300+6165)/4-2)*2/3) * 16, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            nn.Linear(1024, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            \n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, mol, seq):\n",
    "        mol = self.molcnn(mol.reshape(-1,1,self.molshape))\n",
    "        seq = self.seqcnn(seq.reshape(-1,1,self.seqshape))\n",
    "        \n",
    "        # put data into lstm        \n",
    "        x = torch.cat((mol,seq),2)\n",
    "        x = self.pool(x)\n",
    "        # print(x.shape)\n",
    "        x = x.reshape(-1,round(((self.molshape+self.seqshape)/4-2)/3),16)\n",
    "\n",
    "        x,_ = self.lstm(x)\n",
    "        # fully connect layer\n",
    "        x = self.mlp(x.flatten(1))\n",
    "        \n",
    "        x = x.flatten()\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepLPI(300,6165)\n",
    "model(torch.randn(512,300),torch.randn(512,6165)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_dataloader, lossfunc, optimizer, scheduler):\n",
    "    model = model.to(\"cuda\")\n",
    "    model.train()\n",
    "    loop_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        step_mol, step_seq, step_label = batch\n",
    "        step_mol, step_seq, step_label = step_mol.to(\"cuda\"), step_seq.to(\"cuda\"), step_label.to(\"cuda\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(step_mol, step_seq)\n",
    "        loss = lossfunc(logits, step_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loop_loss += float(loss.to(\"cpu\"))\n",
    "\n",
    "        if step%20 == 0:\n",
    "            print(\"step \" + str(step) + \" loss: \" + str(float(loss.to(\"cpu\"))))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        return loop_loss/len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "\n",
    "def test_loop(model, val_mol, val_seq, val_classify, writer, epoch):\n",
    "    model.eval()\n",
    "    model = model.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        step_mol, step_seq = val_mol.to(\"cuda\"), val_seq.to(\"cuda\")\n",
    "        logits = model(step_mol,step_seq)\n",
    "    logits = logits.to(\"cpu\")\n",
    "\n",
    "    cm = confusion_matrix(val_classify==1,logits>=0.5)\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "    writer.add_figure(tag='test evaluate', figure=fig, global_step=epoch)\n",
    "\n",
    "    return roc_auc_score(val_classify,logits), accuracy_score(val_classify==1,logits>=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = DeepLPI(300,6165)\n",
    "\n",
    "model.apply(initialize_weights)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0002, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.8, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "epoch: 0\n",
      "step 0 loss: 0.7240897417068481\n",
      "step 20 loss: 0.6287521123886108\n",
      "step 40 loss: 0.5970298051834106\n",
      "step 60 loss: 0.6152560114860535\n",
      "\n",
      "accuracy: 0.712\t auroc:0.6242451158816515\n",
      "use time: 11.681961059570312\n",
      "----------------------------------------\n",
      "epoch: 1\n",
      "step 0 loss: 0.5770841240882874\n",
      "step 20 loss: 0.5800027847290039\n",
      "step 40 loss: 0.5596088171005249\n",
      "step 60 loss: 0.5713719129562378\n",
      "\n",
      "accuracy: 0.718\t auroc:0.6638876954492134\n",
      "use time: 11.657180070877075\n",
      "----------------------------------------\n",
      "epoch: 2\n",
      "step 0 loss: 0.5883461236953735\n",
      "step 20 loss: 0.556243896484375\n",
      "step 40 loss: 0.5684388279914856\n",
      "step 60 loss: 0.5313402414321899\n",
      "\n",
      "accuracy: 0.714\t auroc:0.7037330256672668\n",
      "use time: 11.594128131866455\n",
      "----------------------------------------\n",
      "epoch: 3\n",
      "step 0 loss: 0.5406341552734375\n",
      "step 20 loss: 0.5502029657363892\n",
      "step 40 loss: 0.5264168977737427\n",
      "step 60 loss: 0.5573656558990479\n",
      "\n",
      "accuracy: 0.72\t auroc:0.7032840777983211\n",
      "use time: 11.559108018875122\n",
      "----------------------------------------\n",
      "epoch: 4\n",
      "step 0 loss: 0.5061010122299194\n",
      "step 20 loss: 0.5426288843154907\n",
      "step 40 loss: 0.5261720418930054\n",
      "step 60 loss: 0.5024728775024414\n",
      "\n",
      "accuracy: 0.722\t auroc:0.7210682062843047\n",
      "use time: 11.689101219177246\n",
      "----------------------------------------\n",
      "epoch: 5\n",
      "step 0 loss: 0.5233426094055176\n",
      "step 20 loss: 0.5441426634788513\n",
      "step 40 loss: 0.5310420989990234\n",
      "step 60 loss: 0.496476948261261\n",
      "\n",
      "accuracy: 0.735\t auroc:0.7286520460919812\n",
      "use time: 11.755660057067871\n",
      "----------------------------------------\n",
      "epoch: 6\n",
      "step 0 loss: 0.536078691482544\n",
      "step 20 loss: 0.5484774112701416\n",
      "step 40 loss: 0.5499122142791748\n",
      "step 60 loss: 0.5098694562911987\n",
      "\n",
      "accuracy: 0.732\t auroc:0.7427770080762343\n",
      "use time: 11.680666208267212\n",
      "----------------------------------------\n",
      "epoch: 7\n",
      "step 0 loss: 0.5392773747444153\n",
      "step 20 loss: 0.5258318185806274\n",
      "step 40 loss: 0.5173247456550598\n",
      "step 60 loss: 0.5082814693450928\n",
      "\n",
      "accuracy: 0.728\t auroc:0.7430956162412926\n",
      "use time: 11.66553544998169\n",
      "----------------------------------------\n",
      "epoch: 8\n",
      "step 0 loss: 0.5161722898483276\n",
      "step 20 loss: 0.48158565163612366\n",
      "step 40 loss: 0.4937175512313843\n",
      "step 60 loss: 0.4845317006111145\n",
      "\n",
      "accuracy: 0.734\t auroc:0.7406095070745493\n",
      "use time: 11.748769283294678\n",
      "----------------------------------------\n",
      "epoch: 9\n",
      "step 0 loss: 0.5024281740188599\n",
      "step 20 loss: 0.4988623261451721\n",
      "step 40 loss: 0.5220937728881836\n",
      "step 60 loss: 0.4751184284687042\n",
      "\n",
      "accuracy: 0.746\t auroc:0.7508146231492969\n",
      "use time: 11.794462203979492\n",
      "----------------------------------------\n",
      "epoch: 10\n",
      "step 0 loss: 0.4908304512500763\n",
      "step 20 loss: 0.5073601007461548\n",
      "step 40 loss: 0.5063417553901672\n",
      "step 60 loss: 0.4767560362815857\n",
      "\n",
      "accuracy: 0.741\t auroc:0.7545075814261095\n",
      "use time: 11.719292640686035\n",
      "----------------------------------------\n",
      "epoch: 11\n",
      "step 0 loss: 0.4893093705177307\n",
      "step 20 loss: 0.48983609676361084\n",
      "step 40 loss: 0.5022064447402954\n",
      "step 60 loss: 0.4896611273288727\n",
      "\n",
      "accuracy: 0.738\t auroc:0.7639451414668527\n",
      "use time: 11.738083839416504\n",
      "----------------------------------------\n",
      "epoch: 12\n",
      "step 0 loss: 0.4707413911819458\n",
      "step 20 loss: 0.4788156747817993\n",
      "step 40 loss: 0.47179949283599854\n",
      "step 60 loss: 0.505186915397644\n",
      "\n",
      "accuracy: 0.742\t auroc:0.7533152145053609\n",
      "use time: 11.67557168006897\n",
      "----------------------------------------\n",
      "epoch: 13\n",
      "step 0 loss: 0.5071998834609985\n",
      "step 20 loss: 0.4955679178237915\n",
      "step 40 loss: 0.44072169065475464\n",
      "step 60 loss: 0.47048914432525635\n",
      "\n",
      "accuracy: 0.754\t auroc:0.762178314369711\n",
      "use time: 11.756245374679565\n",
      "----------------------------------------\n",
      "epoch: 14\n",
      "step 0 loss: 0.4524191617965698\n",
      "step 20 loss: 0.45121538639068604\n",
      "step 40 loss: 0.48757678270339966\n",
      "step 60 loss: 0.48047471046447754\n",
      "\n",
      "accuracy: 0.745\t auroc:0.7661029876756569\n",
      "use time: 11.635999202728271\n",
      "----------------------------------------\n",
      "epoch: 15\n",
      "step 0 loss: 0.466499388217926\n",
      "step 20 loss: 0.4523342251777649\n",
      "step 40 loss: 0.42588502168655396\n",
      "step 60 loss: 0.44081658124923706\n",
      "\n",
      "accuracy: 0.751\t auroc:0.7734840768328417\n",
      "use time: 11.605324268341064\n",
      "----------------------------------------\n",
      "epoch: 16\n",
      "step 0 loss: 0.44808441400527954\n",
      "step 20 loss: 0.44002988934516907\n",
      "step 40 loss: 0.4421902298927307\n",
      "step 60 loss: 0.4608893394470215\n",
      "\n",
      "accuracy: 0.75\t auroc:0.7764529256436127\n",
      "use time: 11.642944812774658\n",
      "----------------------------------------\n",
      "epoch: 17\n",
      "step 0 loss: 0.44974616169929504\n",
      "step 20 loss: 0.4352104365825653\n",
      "step 40 loss: 0.4245130717754364\n",
      "step 60 loss: 0.4615568518638611\n",
      "\n",
      "accuracy: 0.758\t auroc:0.7836167819609848\n",
      "use time: 11.545316696166992\n",
      "----------------------------------------\n",
      "epoch: 18\n",
      "step 0 loss: 0.45241424441337585\n",
      "step 20 loss: 0.4694909453392029\n",
      "step 40 loss: 0.46226567029953003\n",
      "step 60 loss: 0.4632137417793274\n",
      "\n",
      "accuracy: 0.762\t auroc:0.7819899493606114\n",
      "use time: 11.552813529968262\n",
      "----------------------------------------\n",
      "epoch: 19\n",
      "step 0 loss: 0.43453094363212585\n",
      "step 20 loss: 0.48240166902542114\n",
      "step 40 loss: 0.45127546787261963\n",
      "step 60 loss: 0.47360774874687195\n",
      "\n",
      "accuracy: 0.763\t auroc:0.783423686103374\n",
      "use time: 11.61699652671814\n",
      "----------------------------------------\n",
      "epoch: 20\n",
      "step 0 loss: 0.4274757504463196\n",
      "step 20 loss: 0.4328646957874298\n",
      "step 40 loss: 0.4393724203109741\n",
      "step 60 loss: 0.4588238000869751\n",
      "\n",
      "accuracy: 0.764\t auroc:0.7852146501827171\n",
      "use time: 11.641491889953613\n",
      "----------------------------------------\n",
      "epoch: 21\n",
      "step 0 loss: 0.4120846688747406\n",
      "step 20 loss: 0.4402410089969635\n",
      "step 40 loss: 0.4160845875740051\n",
      "step 60 loss: 0.46966636180877686\n",
      "\n",
      "accuracy: 0.761\t auroc:0.787546282663371\n",
      "use time: 11.584465026855469\n",
      "----------------------------------------\n",
      "epoch: 22\n",
      "step 0 loss: 0.4227352738380432\n",
      "step 20 loss: 0.4462098479270935\n",
      "step 40 loss: 0.45102471113204956\n",
      "step 60 loss: 0.4599950909614563\n",
      "\n",
      "accuracy: 0.757\t auroc:0.7967617824678614\n",
      "use time: 11.672722101211548\n",
      "----------------------------------------\n",
      "epoch: 23\n",
      "step 0 loss: 0.4292387366294861\n",
      "step 20 loss: 0.4362128973007202\n",
      "step 40 loss: 0.42118096351623535\n",
      "step 60 loss: 0.4659615159034729\n",
      "\n",
      "accuracy: 0.768\t auroc:0.7984610260148395\n",
      "use time: 11.555032730102539\n",
      "----------------------------------------\n",
      "epoch: 24\n",
      "step 0 loss: 0.40539276599884033\n",
      "step 20 loss: 0.44387179613113403\n",
      "step 40 loss: 0.3747897148132324\n",
      "step 60 loss: 0.4160516858100891\n",
      "\n",
      "accuracy: 0.77\t auroc:0.798456198618399\n",
      "use time: 11.582894325256348\n",
      "----------------------------------------\n",
      "epoch: 25\n",
      "step 0 loss: 0.39783430099487305\n",
      "step 20 loss: 0.39137300848960876\n",
      "step 40 loss: 0.4073810577392578\n",
      "step 60 loss: 0.4857942461967468\n",
      "\n",
      "accuracy: 0.778\t auroc:0.8003581928158686\n",
      "use time: 11.589210748672485\n",
      "----------------------------------------\n",
      "epoch: 26\n",
      "step 0 loss: 0.3768160343170166\n",
      "step 20 loss: 0.436285138130188\n",
      "step 40 loss: 0.4073541760444641\n",
      "step 60 loss: 0.45195579528808594\n",
      "\n",
      "accuracy: 0.78\t auroc:0.8033511786088409\n",
      "use time: 11.60886025428772\n",
      "----------------------------------------\n",
      "epoch: 27\n",
      "step 0 loss: 0.38549113273620605\n",
      "step 20 loss: 0.426187127828598\n",
      "step 40 loss: 0.4126600921154022\n",
      "step 60 loss: 0.4422541558742523\n",
      "\n",
      "accuracy: 0.777\t auroc:0.80559109055713\n",
      "use time: 11.546452283859253\n",
      "----------------------------------------\n",
      "epoch: 28\n",
      "step 0 loss: 0.3919000029563904\n",
      "step 20 loss: 0.4393005967140198\n",
      "step 40 loss: 0.40399935841560364\n",
      "step 60 loss: 0.42353567481040955\n",
      "\n",
      "accuracy: 0.784\t auroc:0.8102398733291174\n",
      "use time: 11.629894733428955\n",
      "----------------------------------------\n",
      "epoch: 29\n",
      "step 0 loss: 0.3982134461402893\n",
      "step 20 loss: 0.43079620599746704\n",
      "step 40 loss: 0.4246482849121094\n",
      "step 60 loss: 0.41730546951293945\n",
      "\n",
      "accuracy: 0.778\t auroc:0.8132449276131904\n",
      "use time: 11.578632354736328\n",
      "----------------------------------------\n",
      "epoch: 30\n",
      "step 0 loss: 0.41001078486442566\n",
      "step 20 loss: 0.44067510962486267\n",
      "step 40 loss: 0.4111839532852173\n",
      "step 60 loss: 0.4251943528652191\n",
      "\n",
      "accuracy: 0.781\t auroc:0.8161341243826967\n",
      "use time: 11.57787299156189\n",
      "----------------------------------------\n",
      "epoch: 31\n",
      "step 0 loss: 0.3938876688480377\n",
      "step 20 loss: 0.3918223977088928\n",
      "step 40 loss: 0.3795032799243927\n",
      "step 60 loss: 0.45237207412719727\n",
      "\n",
      "accuracy: 0.78\t auroc:0.8072275779503839\n",
      "use time: 11.584649562835693\n",
      "----------------------------------------\n",
      "epoch: 32\n",
      "step 0 loss: 0.38069599866867065\n",
      "step 20 loss: 0.42226794362068176\n",
      "step 40 loss: 0.4176805019378662\n",
      "step 60 loss: 0.42216309905052185\n",
      "\n",
      "accuracy: 0.788\t auroc:0.8206767044329981\n",
      "use time: 11.635594606399536\n",
      "----------------------------------------\n",
      "epoch: 33\n",
      "step 0 loss: 0.4079282879829407\n",
      "step 20 loss: 0.3875863552093506\n",
      "step 40 loss: 0.3888777494430542\n",
      "step 60 loss: 0.44199830293655396\n",
      "\n",
      "accuracy: 0.79\t auroc:0.8170996036707523\n",
      "use time: 11.53541612625122\n",
      "----------------------------------------\n",
      "epoch: 34\n",
      "step 0 loss: 0.37812715768814087\n",
      "step 20 loss: 0.4349214434623718\n",
      "step 40 loss: 0.4023006558418274\n",
      "step 60 loss: 0.4411318302154541\n",
      "\n",
      "accuracy: 0.783\t auroc:0.8175919981076607\n",
      "use time: 11.583916187286377\n",
      "----------------------------------------\n",
      "epoch: 35\n",
      "step 0 loss: 0.36528512835502625\n",
      "step 20 loss: 0.406058132648468\n",
      "step 40 loss: 0.38725119829177856\n",
      "step 60 loss: 0.41419145464897156\n",
      "\n",
      "accuracy: 0.785\t auroc:0.8228393780382427\n",
      "use time: 11.557602405548096\n",
      "----------------------------------------\n",
      "epoch: 36\n",
      "step 0 loss: 0.362806499004364\n",
      "step 20 loss: 0.39763012528419495\n",
      "step 40 loss: 0.368232399225235\n",
      "step 60 loss: 0.4126928448677063\n",
      "\n",
      "accuracy: 0.798\t auroc:0.8291487851856859\n",
      "use time: 11.570865392684937\n",
      "----------------------------------------\n",
      "epoch: 37\n",
      "step 0 loss: 0.3646087646484375\n",
      "step 20 loss: 0.41218507289886475\n",
      "step 40 loss: 0.3730383515357971\n",
      "step 60 loss: 0.408217191696167\n",
      "\n",
      "accuracy: 0.799\t auroc:0.8356850799658221\n",
      "use time: 11.610118389129639\n",
      "----------------------------------------\n",
      "epoch: 38\n",
      "step 0 loss: 0.371328741312027\n",
      "step 20 loss: 0.3829904794692993\n",
      "step 40 loss: 0.35326874256134033\n",
      "step 60 loss: 0.42383235692977905\n",
      "\n",
      "accuracy: 0.783\t auroc:0.823732446379694\n",
      "use time: 11.596521139144897\n",
      "----------------------------------------\n",
      "epoch: 39\n",
      "step 0 loss: 0.36271941661834717\n",
      "step 20 loss: 0.37385469675064087\n",
      "step 40 loss: 0.3469577431678772\n",
      "step 60 loss: 0.4483377933502197\n",
      "\n",
      "accuracy: 0.794\t auroc:0.8285501880270912\n",
      "use time: 11.612669467926025\n",
      "----------------------------------------\n",
      "epoch: 40\n",
      "step 0 loss: 0.3817371129989624\n",
      "step 20 loss: 0.3940257430076599\n",
      "step 40 loss: 0.36802589893341064\n",
      "step 60 loss: 0.4519527554512024\n",
      "\n",
      "accuracy: 0.784\t auroc:0.8276860840642817\n",
      "use time: 11.56077265739441\n",
      "----------------------------------------\n",
      "epoch: 41\n",
      "step 0 loss: 0.3730473220348358\n",
      "step 20 loss: 0.39030686020851135\n",
      "step 40 loss: 0.37908780574798584\n",
      "step 60 loss: 0.4095228910446167\n",
      "\n",
      "accuracy: 0.8\t auroc:0.8408310845711584\n",
      "use time: 11.570562362670898\n",
      "----------------------------------------\n",
      "epoch: 42\n",
      "step 0 loss: 0.3428021967411041\n",
      "step 20 loss: 0.42525023221969604\n",
      "step 40 loss: 0.38430631160736084\n",
      "step 60 loss: 0.42648422718048096\n",
      "\n",
      "accuracy: 0.793\t auroc:0.8324555517472761\n",
      "use time: 11.555630683898926\n",
      "----------------------------------------\n",
      "epoch: 43\n",
      "step 0 loss: 0.3873820900917053\n",
      "step 20 loss: 0.3944469690322876\n",
      "step 40 loss: 0.3700193166732788\n",
      "step 60 loss: 0.38359636068344116\n",
      "\n",
      "accuracy: 0.798\t auroc:0.8349657978962206\n",
      "use time: 11.677251815795898\n",
      "----------------------------------------\n",
      "epoch: 44\n",
      "step 0 loss: 0.35917967557907104\n",
      "step 20 loss: 0.41589534282684326\n",
      "step 40 loss: 0.38059550523757935\n",
      "step 60 loss: 0.4260053038597107\n",
      "\n",
      "accuracy: 0.803\t auroc:0.8422310295388389\n",
      "use time: 11.604580163955688\n",
      "----------------------------------------\n",
      "epoch: 45\n",
      "step 0 loss: 0.3443511724472046\n",
      "step 20 loss: 0.37422460317611694\n",
      "step 40 loss: 0.33129748702049255\n",
      "step 60 loss: 0.39826053380966187\n",
      "\n",
      "accuracy: 0.795\t auroc:0.8408552215533596\n",
      "use time: 11.62125277519226\n",
      "----------------------------------------\n",
      "epoch: 46\n",
      "step 0 loss: 0.33546069264411926\n",
      "step 20 loss: 0.37964552640914917\n",
      "step 40 loss: 0.3681055009365082\n",
      "step 60 loss: 0.4189426898956299\n",
      "\n",
      "accuracy: 0.8\t auroc:0.842235856935279\n",
      "use time: 11.599636554718018\n",
      "----------------------------------------\n",
      "epoch: 47\n",
      "step 0 loss: 0.3186406195163727\n",
      "step 20 loss: 0.4055650532245636\n",
      "step 40 loss: 0.3440304398536682\n",
      "step 60 loss: 0.3936128318309784\n",
      "\n",
      "accuracy: 0.809\t auroc:0.8483135490535889\n",
      "use time: 11.548622369766235\n",
      "----------------------------------------\n",
      "epoch: 48\n",
      "step 0 loss: 0.34618791937828064\n",
      "step 20 loss: 0.40093088150024414\n",
      "step 40 loss: 0.327544242143631\n",
      "step 60 loss: 0.3828575611114502\n",
      "\n",
      "accuracy: 0.803\t auroc:0.8420475884741082\n",
      "use time: 11.610990285873413\n",
      "----------------------------------------\n",
      "epoch: 49\n",
      "step 0 loss: 0.3571549654006958\n",
      "step 20 loss: 0.42595022916793823\n",
      "step 40 loss: 0.3379139304161072\n",
      "step 60 loss: 0.3912196457386017\n",
      "\n",
      "accuracy: 0.803\t auroc:0.8401069751051166\n",
      "use time: 11.66322135925293\n",
      "----------------------------------------\n",
      "epoch: 50\n",
      "step 0 loss: 0.34141838550567627\n",
      "step 20 loss: 0.36488354206085205\n",
      "step 40 loss: 0.34570634365081787\n",
      "step 60 loss: 0.4000919461250305\n",
      "\n",
      "accuracy: 0.808\t auroc:0.842670322614904\n",
      "use time: 11.605507135391235\n",
      "----------------------------------------\n",
      "epoch: 51\n",
      "step 0 loss: 0.31203263998031616\n",
      "step 20 loss: 0.3844052851200104\n",
      "step 40 loss: 0.35194772481918335\n",
      "step 60 loss: 0.3851243853569031\n",
      "\n",
      "accuracy: 0.807\t auroc:0.8427813527330306\n",
      "use time: 11.56321382522583\n",
      "----------------------------------------\n",
      "epoch: 52\n",
      "step 0 loss: 0.34260842204093933\n",
      "step 20 loss: 0.36106693744659424\n",
      "step 40 loss: 0.37774205207824707\n",
      "step 60 loss: 0.3743315041065216\n",
      "\n",
      "accuracy: 0.803\t auroc:0.8398173313186998\n",
      "use time: 11.5492684841156\n",
      "----------------------------------------\n",
      "epoch: 53\n",
      "step 0 loss: 0.3304031193256378\n",
      "step 20 loss: 0.35247862339019775\n",
      "step 40 loss: 0.3218114376068115\n",
      "step 60 loss: 0.370593398809433\n",
      "\n",
      "accuracy: 0.814\t auroc:0.8495928091102626\n",
      "use time: 11.546895742416382\n",
      "----------------------------------------\n",
      "epoch: 54\n",
      "step 0 loss: 0.3191525340080261\n",
      "step 20 loss: 0.35373789072036743\n",
      "step 40 loss: 0.3250232934951782\n",
      "step 60 loss: 0.36788609623908997\n",
      "\n",
      "accuracy: 0.809\t auroc:0.8471404917186015\n",
      "use time: 11.686251640319824\n",
      "----------------------------------------\n",
      "epoch: 55\n",
      "step 0 loss: 0.33068475127220154\n",
      "step 20 loss: 0.3886934220790863\n",
      "step 40 loss: 0.3296249210834503\n",
      "step 60 loss: 0.39086079597473145\n",
      "\n",
      "accuracy: 0.809\t auroc:0.8401407668801985\n",
      "use time: 11.529791593551636\n",
      "----------------------------------------\n",
      "epoch: 56\n",
      "step 0 loss: 0.30997931957244873\n",
      "step 20 loss: 0.33121877908706665\n",
      "step 40 loss: 0.3257133662700653\n",
      "step 60 loss: 0.35209715366363525\n",
      "\n",
      "accuracy: 0.815\t auroc:0.8521658114129307\n",
      "use time: 11.580988883972168\n",
      "----------------------------------------\n",
      "epoch: 57\n",
      "step 0 loss: 0.3247417211532593\n",
      "step 20 loss: 0.36865317821502686\n",
      "step 40 loss: 0.31567347049713135\n",
      "step 60 loss: 0.3771095275878906\n",
      "\n",
      "accuracy: 0.811\t auroc:0.8575290488580795\n",
      "use time: 11.603731155395508\n",
      "----------------------------------------\n",
      "epoch: 58\n",
      "step 0 loss: 0.32372739911079407\n",
      "step 20 loss: 0.337070107460022\n",
      "step 40 loss: 0.3046163320541382\n",
      "step 60 loss: 0.34806573390960693\n",
      "\n",
      "accuracy: 0.795\t auroc:0.8400176682709715\n",
      "use time: 11.635869264602661\n",
      "----------------------------------------\n",
      "epoch: 59\n",
      "step 0 loss: 0.31989461183547974\n",
      "step 20 loss: 0.37584125995635986\n",
      "step 40 loss: 0.3197248578071594\n",
      "step 60 loss: 0.41078606247901917\n",
      "\n",
      "accuracy: 0.82\t auroc:0.8548594986266057\n",
      "use time: 11.6200692653656\n",
      "----------------------------------------\n",
      "epoch: 60\n",
      "step 0 loss: 0.3035232424736023\n",
      "step 20 loss: 0.36423173546791077\n",
      "step 40 loss: 0.3058641254901886\n",
      "step 60 loss: 0.3571534752845764\n",
      "\n",
      "accuracy: 0.803\t auroc:0.8523878716491833\n",
      "use time: 11.601585626602173\n",
      "----------------------------------------\n",
      "epoch: 61\n",
      "step 0 loss: 0.3034149706363678\n",
      "step 20 loss: 0.34454143047332764\n",
      "step 40 loss: 0.3324863612651825\n",
      "step 60 loss: 0.3720927834510803\n",
      "\n",
      "accuracy: 0.813\t auroc:0.855491887560282\n",
      "use time: 11.56119418144226\n",
      "----------------------------------------\n",
      "epoch: 62\n",
      "step 0 loss: 0.3272598385810852\n",
      "step 20 loss: 0.36064982414245605\n",
      "step 40 loss: 0.32714325189590454\n",
      "step 60 loss: 0.3802509903907776\n",
      "\n",
      "accuracy: 0.82\t auroc:0.8590448513403266\n",
      "use time: 11.55996823310852\n",
      "----------------------------------------\n",
      "epoch: 63\n",
      "step 0 loss: 0.3237084448337555\n",
      "step 20 loss: 0.34818553924560547\n",
      "step 40 loss: 0.3275507688522339\n",
      "step 60 loss: 0.35926884412765503\n",
      "\n",
      "accuracy: 0.814\t auroc:0.8613957934067419\n",
      "use time: 11.551127433776855\n",
      "----------------------------------------\n",
      "epoch: 64\n",
      "step 0 loss: 0.2779679298400879\n",
      "step 20 loss: 0.3740156292915344\n",
      "step 40 loss: 0.26238617300987244\n",
      "step 60 loss: 0.3787645101547241\n",
      "\n",
      "accuracy: 0.817\t auroc:0.8614971687319878\n",
      "use time: 11.55927038192749\n",
      "----------------------------------------\n",
      "epoch: 65\n",
      "step 0 loss: 0.306868314743042\n",
      "step 20 loss: 0.3756881356239319\n",
      "step 40 loss: 0.31575870513916016\n",
      "step 60 loss: 0.3803448975086212\n",
      "\n",
      "accuracy: 0.821\t auroc:0.8580455802771891\n",
      "use time: 11.636739730834961\n",
      "----------------------------------------\n",
      "epoch: 66\n",
      "step 0 loss: 0.2827707827091217\n",
      "step 20 loss: 0.35150080919265747\n",
      "step 40 loss: 0.28650033473968506\n",
      "step 60 loss: 0.38130515813827515\n",
      "\n",
      "accuracy: 0.815\t auroc:0.8571380297464168\n",
      "use time: 11.619540691375732\n",
      "----------------------------------------\n",
      "epoch: 67\n",
      "step 0 loss: 0.30376923084259033\n",
      "step 20 loss: 0.3511573076248169\n",
      "step 40 loss: 0.2997974157333374\n",
      "step 60 loss: 0.3480544090270996\n",
      "\n",
      "accuracy: 0.826\t auroc:0.8664886966512352\n",
      "use time: 11.74478030204773\n",
      "----------------------------------------\n",
      "epoch: 68\n",
      "step 0 loss: 0.26723814010620117\n",
      "step 20 loss: 0.33025485277175903\n",
      "step 40 loss: 0.300523579120636\n",
      "step 60 loss: 0.3759547472000122\n",
      "\n",
      "accuracy: 0.815\t auroc:0.8649680667725476\n",
      "use time: 11.63360857963562\n",
      "----------------------------------------\n",
      "epoch: 69\n",
      "step 0 loss: 0.31637048721313477\n",
      "step 20 loss: 0.3634874224662781\n",
      "step 40 loss: 0.3103751540184021\n",
      "step 60 loss: 0.3657897710800171\n",
      "\n",
      "accuracy: 0.818\t auroc:0.864089480620417\n",
      "use time: 11.6055908203125\n",
      "----------------------------------------\n",
      "epoch: 70\n",
      "step 0 loss: 0.29493147134780884\n",
      "step 20 loss: 0.32958415150642395\n",
      "step 40 loss: 0.2985401153564453\n",
      "step 60 loss: 0.38231170177459717\n",
      "\n",
      "accuracy: 0.82\t auroc:0.8682313867661754\n",
      "use time: 11.607004404067993\n",
      "----------------------------------------\n",
      "epoch: 71\n",
      "step 0 loss: 0.2851411700248718\n",
      "step 20 loss: 0.31136730313301086\n",
      "step 40 loss: 0.28745540976524353\n",
      "step 60 loss: 0.3480204641819\n",
      "\n",
      "accuracy: 0.822\t auroc:0.8692258304328726\n",
      "use time: 11.63301157951355\n",
      "----------------------------------------\n",
      "epoch: 72\n",
      "step 0 loss: 0.2818708121776581\n",
      "step 20 loss: 0.3428857922554016\n",
      "step 40 loss: 0.3089090585708618\n",
      "step 60 loss: 0.36540770530700684\n",
      "\n",
      "accuracy: 0.822\t auroc:0.8685837867063156\n",
      "use time: 11.669760942459106\n",
      "----------------------------------------\n",
      "epoch: 73\n",
      "step 0 loss: 0.26912808418273926\n",
      "step 20 loss: 0.30936992168426514\n",
      "step 40 loss: 0.2564079165458679\n",
      "step 60 loss: 0.341772198677063\n",
      "\n",
      "accuracy: 0.82\t auroc:0.8634329547045392\n",
      "use time: 11.64914345741272\n",
      "----------------------------------------\n",
      "epoch: 74\n",
      "step 0 loss: 0.3024016320705414\n",
      "step 20 loss: 0.31353136897087097\n",
      "step 40 loss: 0.2802984416484833\n",
      "step 60 loss: 0.3341469466686249\n",
      "\n",
      "accuracy: 0.817\t auroc:0.8724070846870158\n",
      "use time: 11.623903036117554\n",
      "----------------------------------------\n",
      "epoch: 75\n",
      "step 0 loss: 0.2621099352836609\n",
      "step 20 loss: 0.31635114550590515\n",
      "step 40 loss: 0.27031219005584717\n",
      "step 60 loss: 0.34509268403053284\n",
      "\n",
      "accuracy: 0.819\t auroc:0.8729187887096851\n",
      "use time: 11.583457469940186\n",
      "----------------------------------------\n",
      "epoch: 76\n",
      "step 0 loss: 0.23848381638526917\n",
      "step 20 loss: 0.3044242560863495\n",
      "step 40 loss: 0.2718157172203064\n",
      "step 60 loss: 0.3413240611553192\n",
      "\n",
      "accuracy: 0.821\t auroc:0.870760942500881\n",
      "use time: 11.571286916732788\n",
      "----------------------------------------\n",
      "epoch: 77\n",
      "step 0 loss: 0.2591403126716614\n",
      "step 20 loss: 0.3313005268573761\n",
      "step 40 loss: 0.2599717080593109\n",
      "step 60 loss: 0.37210795283317566\n",
      "\n",
      "accuracy: 0.826\t auroc:0.8738408214297783\n",
      "use time: 11.575724124908447\n",
      "----------------------------------------\n",
      "epoch: 78\n",
      "step 0 loss: 0.25974521040916443\n",
      "step 20 loss: 0.31564217805862427\n",
      "step 40 loss: 0.25504714250564575\n",
      "step 60 loss: 0.3611747622489929\n",
      "\n",
      "accuracy: 0.822\t auroc:0.869631331733856\n",
      "use time: 11.604362964630127\n",
      "----------------------------------------\n",
      "epoch: 79\n",
      "step 0 loss: 0.25480106472969055\n",
      "step 20 loss: 0.3278522491455078\n",
      "step 40 loss: 0.29036790132522583\n",
      "step 60 loss: 0.34456267952919006\n",
      "\n",
      "accuracy: 0.822\t auroc:0.8758635005382548\n",
      "use time: 11.566216707229614\n",
      "----------------------------------------\n",
      "epoch: 80\n",
      "step 0 loss: 0.2551921010017395\n",
      "step 20 loss: 0.31263166666030884\n",
      "step 40 loss: 0.271589994430542\n",
      "step 60 loss: 0.32325035333633423\n",
      "\n",
      "accuracy: 0.817\t auroc:0.8766696757437812\n",
      "use time: 11.77720594406128\n",
      "----------------------------------------\n",
      "epoch: 81\n",
      "step 0 loss: 0.25028616189956665\n",
      "step 20 loss: 0.30161961913108826\n",
      "step 40 loss: 0.2769714593887329\n",
      "step 60 loss: 0.29282552003860474\n",
      "\n",
      "accuracy: 0.817\t auroc:0.8768289798263105\n",
      "use time: 11.605823755264282\n",
      "----------------------------------------\n",
      "epoch: 82\n",
      "step 0 loss: 0.2641884386539459\n",
      "step 20 loss: 0.2935134172439575\n",
      "step 40 loss: 0.24162322282791138\n",
      "step 60 loss: 0.3135703206062317\n",
      "\n",
      "accuracy: 0.82\t auroc:0.8783206453263561\n",
      "use time: 11.663097858428955\n",
      "----------------------------------------\n",
      "epoch: 83\n",
      "step 0 loss: 0.2768792510032654\n",
      "step 20 loss: 0.3172625005245209\n",
      "step 40 loss: 0.2546382248401642\n",
      "step 60 loss: 0.3366782069206238\n",
      "\n",
      "accuracy: 0.803\t auroc:0.8751490458650936\n",
      "use time: 11.725589275360107\n",
      "----------------------------------------\n",
      "epoch: 84\n",
      "step 0 loss: 0.2572712302207947\n",
      "step 20 loss: 0.3261812925338745\n",
      "step 40 loss: 0.2608816623687744\n",
      "step 60 loss: 0.2952420115470886\n",
      "\n",
      "accuracy: 0.822\t auroc:0.8779585905933354\n",
      "use time: 11.617506980895996\n",
      "----------------------------------------\n",
      "epoch: 85\n",
      "step 0 loss: 0.25334522128105164\n",
      "step 20 loss: 0.2861484885215759\n",
      "step 40 loss: 0.26456159353256226\n",
      "step 60 loss: 0.325530469417572\n",
      "\n",
      "accuracy: 0.818\t auroc:0.8754483444443909\n",
      "use time: 11.604127407073975\n",
      "----------------------------------------\n",
      "epoch: 86\n",
      "step 0 loss: 0.22876976430416107\n",
      "step 20 loss: 0.3184657096862793\n",
      "step 40 loss: 0.23444876074790955\n",
      "step 60 loss: 0.3126537799835205\n",
      "\n",
      "accuracy: 0.815\t auroc:0.8754435170479505\n",
      "use time: 11.626044273376465\n",
      "----------------------------------------\n",
      "epoch: 87\n",
      "step 0 loss: 0.24165880680084229\n",
      "step 20 loss: 0.3028404712677002\n",
      "step 40 loss: 0.23903325200080872\n",
      "step 60 loss: 0.36513668298721313\n",
      "\n",
      "accuracy: 0.805\t auroc:0.8792812972179714\n",
      "use time: 11.609671592712402\n",
      "----------------------------------------\n",
      "epoch: 88\n",
      "step 0 loss: 0.2318059653043747\n",
      "step 20 loss: 0.293247789144516\n",
      "step 40 loss: 0.26256072521209717\n",
      "step 60 loss: 0.3344465494155884\n",
      "\n",
      "accuracy: 0.812\t auroc:0.8824818610578756\n",
      "use time: 11.68479871749878\n",
      "----------------------------------------\n",
      "epoch: 89\n",
      "step 0 loss: 0.23297251760959625\n",
      "step 20 loss: 0.3463955521583557\n",
      "step 40 loss: 0.2615872621536255\n",
      "step 60 loss: 0.3146265745162964\n",
      "\n",
      "accuracy: 0.82\t auroc:0.8819411926565646\n",
      "use time: 11.631555080413818\n",
      "----------------------------------------\n",
      "epoch: 90\n",
      "step 0 loss: 0.23955826461315155\n",
      "step 20 loss: 0.29470792412757874\n",
      "step 40 loss: 0.22823019325733185\n",
      "step 60 loss: 0.30252087116241455\n",
      "\n",
      "accuracy: 0.824\t auroc:0.8834569951388118\n",
      "use time: 11.656729221343994\n",
      "----------------------------------------\n",
      "epoch: 91\n",
      "step 0 loss: 0.23298607766628265\n",
      "step 20 loss: 0.3126165270805359\n",
      "step 40 loss: 0.23417988419532776\n",
      "step 60 loss: 0.28976887464523315\n",
      "\n",
      "accuracy: 0.815\t auroc:0.8723877751012546\n",
      "use time: 11.642738342285156\n",
      "----------------------------------------\n",
      "epoch: 92\n",
      "step 0 loss: 0.24649149179458618\n",
      "step 20 loss: 0.2943861782550812\n",
      "step 40 loss: 0.22783944010734558\n",
      "step 60 loss: 0.3034548759460449\n",
      "\n",
      "accuracy: 0.82\t auroc:0.8799860970982519\n",
      "use time: 11.651418924331665\n",
      "----------------------------------------\n",
      "epoch: 93\n",
      "step 0 loss: 0.23256248235702515\n",
      "step 20 loss: 0.26159390807151794\n",
      "step 40 loss: 0.24046437442302704\n",
      "step 60 loss: 0.27729105949401855\n",
      "\n",
      "accuracy: 0.807\t auroc:0.8843790278589048\n",
      "use time: 11.668369770050049\n",
      "----------------------------------------\n",
      "epoch: 94\n",
      "step 0 loss: 0.21640777587890625\n",
      "step 20 loss: 0.3058685064315796\n",
      "step 40 loss: 0.22578676044940948\n",
      "step 60 loss: 0.3103736937046051\n",
      "\n",
      "accuracy: 0.822\t auroc:0.8844562662019493\n",
      "use time: 11.63233208656311\n",
      "----------------------------------------\n",
      "epoch: 95\n",
      "step 0 loss: 0.21813401579856873\n",
      "step 20 loss: 0.29182112216949463\n",
      "step 40 loss: 0.22645556926727295\n",
      "step 60 loss: 0.3054881691932678\n",
      "\n",
      "accuracy: 0.808\t auroc:0.8801502285772215\n",
      "use time: 11.813533306121826\n",
      "----------------------------------------\n",
      "epoch: 96\n",
      "step 0 loss: 0.22872288525104523\n",
      "step 20 loss: 0.2796381413936615\n",
      "step 40 loss: 0.2547791302204132\n",
      "step 60 loss: 0.29702138900756836\n",
      "\n",
      "accuracy: 0.823\t auroc:0.8826894391048077\n",
      "use time: 11.646535396575928\n",
      "----------------------------------------\n",
      "epoch: 97\n",
      "step 0 loss: 0.23108376562595367\n",
      "step 20 loss: 0.27406132221221924\n",
      "step 40 loss: 0.2405480444431305\n",
      "step 60 loss: 0.3009025454521179\n",
      "\n",
      "accuracy: 0.827\t auroc:0.892392505949766\n",
      "use time: 11.768195629119873\n",
      "----------------------------------------\n",
      "epoch: 98\n",
      "step 0 loss: 0.2166966199874878\n",
      "step 20 loss: 0.2845922112464905\n",
      "step 40 loss: 0.2177410125732422\n",
      "step 60 loss: 0.25633105635643005\n",
      "\n",
      "accuracy: 0.816\t auroc:0.884885904485134\n",
      "use time: 11.68653655052185\n",
      "----------------------------------------\n",
      "epoch: 99\n",
      "step 0 loss: 0.21334373950958252\n",
      "step 20 loss: 0.2817646265029907\n",
      "step 40 loss: 0.236866757273674\n",
      "step 60 loss: 0.3381515443325043\n",
      "\n",
      "accuracy: 0.817\t auroc:0.8801357463879006\n",
      "use time: 11.686372518539429\n",
      "----------------------------------------\n",
      "epoch: 100\n",
      "step 0 loss: 0.2121116816997528\n",
      "step 20 loss: 0.26347023248672485\n",
      "step 40 loss: 0.2397814393043518\n",
      "step 60 loss: 0.3218407928943634\n",
      "\n",
      "accuracy: 0.822\t auroc:0.8881347422894411\n",
      "use time: 11.633405447006226\n",
      "----------------------------------------\n",
      "epoch: 101\n",
      "step 0 loss: 0.2206142395734787\n",
      "step 20 loss: 0.26489317417144775\n",
      "step 40 loss: 0.20590540766716003\n",
      "step 60 loss: 0.2867123484611511\n",
      "\n",
      "accuracy: 0.824\t auroc:0.8867106603395591\n",
      "use time: 11.617059230804443\n",
      "----------------------------------------\n",
      "epoch: 102\n",
      "step 0 loss: 0.19849064946174622\n",
      "step 20 loss: 0.25138169527053833\n",
      "step 40 loss: 0.23436382412910461\n",
      "step 60 loss: 0.31585705280303955\n",
      "\n",
      "accuracy: 0.813\t auroc:0.880734343546495\n",
      "use time: 11.59862494468689\n",
      "----------------------------------------\n",
      "epoch: 103\n",
      "step 0 loss: 0.18766099214553833\n",
      "step 20 loss: 0.2813381254673004\n",
      "step 40 loss: 0.21123945713043213\n",
      "step 60 loss: 0.2836529016494751\n",
      "\n",
      "accuracy: 0.823\t auroc:0.8880575039463966\n",
      "use time: 11.639711141586304\n",
      "----------------------------------------\n",
      "epoch: 104\n",
      "step 0 loss: 0.2150869518518448\n",
      "step 20 loss: 0.27964141964912415\n",
      "step 40 loss: 0.21206256747245789\n",
      "step 60 loss: 0.2450985312461853\n",
      "\n",
      "accuracy: 0.826\t auroc:0.8837707759074297\n",
      "use time: 11.576363563537598\n",
      "----------------------------------------\n",
      "epoch: 105\n",
      "step 0 loss: 0.24337658286094666\n",
      "step 20 loss: 0.2899845242500305\n",
      "step 40 loss: 0.21314598619937897\n",
      "step 60 loss: 0.28118884563446045\n",
      "\n",
      "accuracy: 0.819\t auroc:0.8897229557182925\n",
      "use time: 11.617534875869751\n",
      "----------------------------------------\n",
      "epoch: 106\n",
      "step 0 loss: 0.18198156356811523\n",
      "step 20 loss: 0.26255905628204346\n",
      "step 40 loss: 0.238186776638031\n",
      "step 60 loss: 0.2629449665546417\n",
      "\n",
      "accuracy: 0.825\t auroc:0.891330478732905\n",
      "use time: 11.604621410369873\n",
      "----------------------------------------\n",
      "epoch: 107\n",
      "step 0 loss: 0.2139502912759781\n",
      "step 20 loss: 0.24756190180778503\n",
      "step 40 loss: 0.1974426507949829\n",
      "step 60 loss: 0.26503077149391174\n",
      "\n",
      "accuracy: 0.816\t auroc:0.885894830341152\n",
      "use time: 11.574546098709106\n",
      "----------------------------------------\n",
      "epoch: 108\n",
      "step 0 loss: 0.20155927538871765\n",
      "step 20 loss: 0.23791518807411194\n",
      "step 40 loss: 0.18308784067630768\n",
      "step 60 loss: 0.24647106230258942\n",
      "\n",
      "accuracy: 0.823\t auroc:0.8847362551954854\n",
      "use time: 11.624659299850464\n",
      "----------------------------------------\n",
      "epoch: 109\n",
      "step 0 loss: 0.19435611367225647\n",
      "step 20 loss: 0.2664044499397278\n",
      "step 40 loss: 0.2151363492012024\n",
      "step 60 loss: 0.25220513343811035\n",
      "\n",
      "accuracy: 0.823\t auroc:0.8905822322846619\n",
      "use time: 11.587622165679932\n",
      "----------------------------------------\n",
      "epoch: 110\n",
      "step 0 loss: 0.18810713291168213\n",
      "step 20 loss: 0.23867857456207275\n",
      "step 40 loss: 0.2103579044342041\n",
      "step 60 loss: 0.3061578869819641\n",
      "\n",
      "accuracy: 0.83\t auroc:0.8929476565403981\n",
      "use time: 11.600117206573486\n",
      "----------------------------------------\n",
      "epoch: 111\n",
      "step 0 loss: 0.22251397371292114\n",
      "step 20 loss: 0.29086822271347046\n",
      "step 40 loss: 0.1607353389263153\n",
      "step 60 loss: 0.24308353662490845\n",
      "\n",
      "accuracy: 0.816\t auroc:0.8897229557182925\n",
      "use time: 11.826534509658813\n",
      "----------------------------------------\n",
      "epoch: 112\n",
      "step 0 loss: 0.17482757568359375\n",
      "step 20 loss: 0.22686591744422913\n",
      "step 40 loss: 0.1920711100101471\n",
      "step 60 loss: 0.2521759271621704\n",
      "\n",
      "accuracy: 0.831\t auroc:0.8933193660662994\n",
      "use time: 11.651144027709961\n",
      "----------------------------------------\n",
      "epoch: 113\n",
      "step 0 loss: 0.20747163891792297\n",
      "step 20 loss: 0.22647128999233246\n",
      "step 40 loss: 0.19177530705928802\n",
      "step 60 loss: 0.23316405713558197\n",
      "\n",
      "accuracy: 0.819\t auroc:0.8910215253607272\n",
      "use time: 11.566782474517822\n",
      "----------------------------------------\n",
      "epoch: 114\n",
      "step 0 loss: 0.17484606802463531\n",
      "step 20 loss: 0.28079497814178467\n",
      "step 40 loss: 0.19804370403289795\n",
      "step 60 loss: 0.24928662180900574\n",
      "\n",
      "accuracy: 0.816\t auroc:0.8909201500354813\n",
      "use time: 11.584726095199585\n",
      "----------------------------------------\n",
      "epoch: 115\n",
      "step 0 loss: 0.1892666518688202\n",
      "step 20 loss: 0.18281270563602448\n",
      "step 40 loss: 0.17795756459236145\n",
      "step 60 loss: 0.29913926124572754\n",
      "\n",
      "accuracy: 0.828\t auroc:0.897166801029201\n",
      "use time: 11.62724232673645\n",
      "----------------------------------------\n",
      "epoch: 116\n",
      "step 0 loss: 0.1689542979001999\n",
      "step 20 loss: 0.21170368790626526\n",
      "step 40 loss: 0.2106298804283142\n",
      "step 60 loss: 0.26005077362060547\n",
      "\n",
      "accuracy: 0.805\t auroc:0.8911953116325771\n",
      "use time: 11.618262767791748\n",
      "----------------------------------------\n",
      "epoch: 117\n",
      "step 0 loss: 0.18227353692054749\n",
      "step 20 loss: 0.24212409555912018\n",
      "step 40 loss: 0.17772650718688965\n",
      "step 60 loss: 0.25929728150367737\n",
      "\n",
      "accuracy: 0.818\t auroc:0.8881733614609634\n",
      "use time: 11.683034420013428\n",
      "----------------------------------------\n",
      "epoch: 118\n",
      "step 0 loss: 0.14982685446739197\n",
      "step 20 loss: 0.26105010509490967\n",
      "step 40 loss: 0.17419159412384033\n",
      "step 60 loss: 0.25534534454345703\n",
      "\n",
      "accuracy: 0.823\t auroc:0.8906691254205868\n",
      "use time: 11.681028366088867\n",
      "----------------------------------------\n",
      "epoch: 119\n",
      "step 0 loss: 0.1568080186843872\n",
      "step 20 loss: 0.22447910904884338\n",
      "step 40 loss: 0.17578868567943573\n",
      "step 60 loss: 0.23369088768959045\n",
      "\n",
      "accuracy: 0.823\t auroc:0.8874589067878021\n",
      "use time: 11.684259176254272\n",
      "----------------------------------------\n",
      "epoch: 120\n",
      "step 0 loss: 0.20380716025829315\n",
      "step 20 loss: 0.24480889737606049\n",
      "step 40 loss: 0.20476111769676208\n",
      "step 60 loss: 0.2408837378025055\n",
      "\n",
      "accuracy: 0.817\t auroc:0.8975964393123856\n",
      "use time: 11.620566606521606\n",
      "----------------------------------------\n",
      "epoch: 121\n",
      "step 0 loss: 0.17500734329223633\n",
      "step 20 loss: 0.2584872543811798\n",
      "step 40 loss: 0.1936684548854828\n",
      "step 60 loss: 0.2342526763677597\n",
      "\n",
      "accuracy: 0.83\t auroc:0.8969157764143064\n",
      "use time: 11.645284175872803\n",
      "----------------------------------------\n",
      "epoch: 122\n",
      "step 0 loss: 0.1802295744419098\n",
      "step 20 loss: 0.24160271883010864\n",
      "step 40 loss: 0.19570276141166687\n",
      "step 60 loss: 0.2609226107597351\n",
      "\n",
      "accuracy: 0.822\t auroc:0.8885595531761855\n",
      "use time: 11.677512645721436\n",
      "----------------------------------------\n",
      "epoch: 123\n",
      "step 0 loss: 0.1753862351179123\n",
      "step 20 loss: 0.23001012206077576\n",
      "step 40 loss: 0.1579061895608902\n",
      "step 60 loss: 0.2173565775156021\n",
      "\n",
      "accuracy: 0.829\t auroc:0.891977349855902\n",
      "use time: 11.680909633636475\n",
      "----------------------------------------\n",
      "epoch: 124\n",
      "step 0 loss: 0.13669297099113464\n",
      "step 20 loss: 0.19821256399154663\n",
      "step 40 loss: 0.16356933116912842\n",
      "step 60 loss: 0.21774324774742126\n",
      "\n",
      "accuracy: 0.815\t auroc:0.8881830162538439\n",
      "use time: 11.685511589050293\n",
      "----------------------------------------\n",
      "epoch: 125\n",
      "step 0 loss: 0.19850529730319977\n",
      "step 20 loss: 0.2005169838666916\n",
      "step 40 loss: 0.17016443610191345\n",
      "step 60 loss: 0.2061212658882141\n",
      "\n",
      "accuracy: 0.835\t auroc:0.8917456348267689\n",
      "use time: 11.688639640808105\n",
      "----------------------------------------\n",
      "epoch: 126\n",
      "step 0 loss: 0.16623936593532562\n",
      "step 20 loss: 0.24348270893096924\n",
      "step 40 loss: 0.16759535670280457\n",
      "step 60 loss: 0.23110349476337433\n",
      "\n",
      "accuracy: 0.833\t auroc:0.8919435580808203\n",
      "use time: 11.687581777572632\n",
      "----------------------------------------\n",
      "epoch: 127\n",
      "step 0 loss: 0.16485793888568878\n",
      "step 20 loss: 0.18972247838974\n",
      "step 40 loss: 0.15727177262306213\n",
      "step 60 loss: 0.22963759303092957\n",
      "\n",
      "accuracy: 0.835\t auroc:0.8952310150566495\n",
      "use time: 11.682702779769897\n",
      "----------------------------------------\n",
      "epoch: 128\n",
      "step 0 loss: 0.16040712594985962\n",
      "step 20 loss: 0.20122578740119934\n",
      "step 40 loss: 0.14214016497135162\n",
      "step 60 loss: 0.2025163471698761\n",
      "\n",
      "accuracy: 0.83\t auroc:0.8892015969027424\n",
      "use time: 11.94405198097229\n",
      "----------------------------------------\n",
      "epoch: 129\n",
      "step 0 loss: 0.1439674198627472\n",
      "step 20 loss: 0.20183444023132324\n",
      "step 40 loss: 0.18283456563949585\n",
      "step 60 loss: 0.22694042325019836\n",
      "\n",
      "accuracy: 0.825\t auroc:0.8916297773122023\n",
      "use time: 11.684750080108643\n",
      "----------------------------------------\n",
      "epoch: 130\n",
      "step 0 loss: 0.16271907091140747\n",
      "step 20 loss: 0.23670384287834167\n",
      "step 40 loss: 0.17758242785930634\n",
      "step 60 loss: 0.18515023589134216\n",
      "\n",
      "accuracy: 0.831\t auroc:0.8949558534595536\n",
      "use time: 11.706596374511719\n",
      "----------------------------------------\n",
      "epoch: 131\n",
      "step 0 loss: 0.17017453908920288\n",
      "step 20 loss: 0.1708947718143463\n",
      "step 40 loss: 0.15727850794792175\n",
      "step 60 loss: 0.18921330571174622\n",
      "\n",
      "accuracy: 0.828\t auroc:0.8994405047525718\n",
      "use time: 11.722538471221924\n",
      "----------------------------------------\n",
      "epoch: 132\n",
      "step 0 loss: 0.1636897623538971\n",
      "step 20 loss: 0.17974373698234558\n",
      "step 40 loss: 0.17705368995666504\n",
      "step 60 loss: 0.22749996185302734\n",
      "\n",
      "accuracy: 0.831\t auroc:0.8947724123948232\n",
      "use time: 11.731589794158936\n",
      "----------------------------------------\n",
      "epoch: 133\n",
      "step 0 loss: 0.164230614900589\n",
      "step 20 loss: 0.1736389696598053\n",
      "step 40 loss: 0.1488562971353531\n",
      "step 60 loss: 0.1858418732881546\n",
      "\n",
      "accuracy: 0.825\t auroc:0.8947482754126217\n",
      "use time: 11.676644563674927\n",
      "----------------------------------------\n",
      "epoch: 134\n",
      "step 0 loss: 0.1272876262664795\n",
      "step 20 loss: 0.1983245611190796\n",
      "step 40 loss: 0.17496363818645477\n",
      "step 60 loss: 0.18692469596862793\n",
      "\n",
      "accuracy: 0.818\t auroc:0.8785475329590491\n",
      "use time: 11.689422607421875\n",
      "----------------------------------------\n",
      "epoch: 135\n",
      "step 0 loss: 0.12343794107437134\n",
      "step 20 loss: 0.17933711409568787\n",
      "step 40 loss: 0.1428428739309311\n",
      "step 60 loss: 0.21072955429553986\n",
      "\n",
      "accuracy: 0.817\t auroc:0.8923345771924828\n",
      "use time: 11.664309024810791\n",
      "----------------------------------------\n",
      "epoch: 136\n",
      "step 0 loss: 0.15544067323207855\n",
      "step 20 loss: 0.1997380256652832\n",
      "step 40 loss: 0.14554929733276367\n",
      "step 60 loss: 0.2200995832681656\n",
      "\n",
      "accuracy: 0.844\t auroc:0.901458356464608\n",
      "use time: 11.653223991394043\n",
      "----------------------------------------\n",
      "epoch: 137\n",
      "step 0 loss: 0.11806046962738037\n",
      "step 20 loss: 0.18386663496494293\n",
      "step 40 loss: 0.1445091962814331\n",
      "step 60 loss: 0.22497522830963135\n",
      "\n",
      "accuracy: 0.834\t auroc:0.9034279342122413\n",
      "use time: 11.715873956680298\n",
      "----------------------------------------\n",
      "epoch: 138\n",
      "step 0 loss: 0.16873511672019958\n",
      "step 20 loss: 0.21427404880523682\n",
      "step 40 loss: 0.14238578081130981\n",
      "step 60 loss: 0.20936498045921326\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8973164503188495\n",
      "use time: 11.698594331741333\n",
      "----------------------------------------\n",
      "epoch: 139\n",
      "step 0 loss: 0.15919014811515808\n",
      "step 20 loss: 0.18900495767593384\n",
      "step 40 loss: 0.1511964052915573\n",
      "step 60 loss: 0.18983349204063416\n",
      "\n",
      "accuracy: 0.828\t auroc:0.8981902090745397\n",
      "use time: 11.70966362953186\n",
      "----------------------------------------\n",
      "epoch: 140\n",
      "step 0 loss: 0.13642188906669617\n",
      "step 20 loss: 0.19093364477157593\n",
      "step 40 loss: 0.16343194246292114\n",
      "step 60 loss: 0.20265094935894012\n",
      "\n",
      "accuracy: 0.83\t auroc:0.8928945551795551\n",
      "use time: 11.684317111968994\n",
      "----------------------------------------\n",
      "epoch: 141\n",
      "step 0 loss: 0.15113702416419983\n",
      "step 20 loss: 0.2234189659357071\n",
      "step 40 loss: 0.14458204805850983\n",
      "step 60 loss: 0.15279991924762726\n",
      "\n",
      "accuracy: 0.821\t auroc:0.8971281818576788\n",
      "use time: 11.68117380142212\n",
      "----------------------------------------\n",
      "epoch: 142\n",
      "step 0 loss: 0.15147936344146729\n",
      "step 20 loss: 0.16653352975845337\n",
      "step 40 loss: 0.1578502357006073\n",
      "step 60 loss: 0.24361547827720642\n",
      "\n",
      "accuracy: 0.832\t auroc:0.9011059565244677\n",
      "use time: 11.738444566726685\n",
      "----------------------------------------\n",
      "epoch: 143\n",
      "step 0 loss: 0.10013959556818008\n",
      "step 20 loss: 0.20799855887889862\n",
      "step 40 loss: 0.16557399928569794\n",
      "step 60 loss: 0.1813395917415619\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8975433379515426\n",
      "use time: 11.745463371276855\n",
      "----------------------------------------\n",
      "epoch: 144\n",
      "step 0 loss: 0.15465044975280762\n",
      "step 20 loss: 0.18985098600387573\n",
      "step 40 loss: 0.14963489770889282\n",
      "step 60 loss: 0.21184982359409332\n",
      "\n",
      "accuracy: 0.836\t auroc:0.8975529927444232\n",
      "use time: 11.725139141082764\n",
      "----------------------------------------\n",
      "epoch: 145\n",
      "step 0 loss: 0.1481991857290268\n",
      "step 20 loss: 0.15356092154979706\n",
      "step 40 loss: 0.15194553136825562\n",
      "step 60 loss: 0.20862241089344025\n",
      "\n",
      "accuracy: 0.837\t auroc:0.8973019681295287\n",
      "use time: 11.68742060661316\n",
      "----------------------------------------\n",
      "epoch: 146\n",
      "step 0 loss: 0.14191269874572754\n",
      "step 20 loss: 0.2480791211128235\n",
      "step 40 loss: 0.13303476572036743\n",
      "step 60 loss: 0.1779683232307434\n",
      "\n",
      "accuracy: 0.827\t auroc:0.8919966594416633\n",
      "use time: 11.751040697097778\n",
      "----------------------------------------\n",
      "epoch: 147\n",
      "step 0 loss: 0.12317733466625214\n",
      "step 20 loss: 0.2033618837594986\n",
      "step 40 loss: 0.14079460501670837\n",
      "step 60 loss: 0.1846725046634674\n",
      "\n",
      "accuracy: 0.832\t auroc:0.8995515348706982\n",
      "use time: 12.02699589729309\n",
      "----------------------------------------\n",
      "epoch: 148\n",
      "step 0 loss: 0.08835352957248688\n",
      "step 20 loss: 0.12377379834651947\n",
      "step 40 loss: 0.14114774763584137\n",
      "step 60 loss: 0.2455976903438568\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9002756443367398\n",
      "use time: 11.753172397613525\n",
      "----------------------------------------\n",
      "epoch: 149\n",
      "step 0 loss: 0.14940676093101501\n",
      "step 20 loss: 0.15854285657405853\n",
      "step 40 loss: 0.14587248861789703\n",
      "step 60 loss: 0.24267809092998505\n",
      "\n",
      "accuracy: 0.831\t auroc:0.8958054752330427\n",
      "use time: 11.66589617729187\n",
      "----------------------------------------\n",
      "epoch: 150\n",
      "step 0 loss: 0.11865472048521042\n",
      "step 20 loss: 0.15518343448638916\n",
      "step 40 loss: 0.14347441494464874\n",
      "step 60 loss: 0.173465758562088\n",
      "\n",
      "accuracy: 0.828\t auroc:0.8977364338091537\n",
      "use time: 11.687268495559692\n",
      "----------------------------------------\n",
      "epoch: 151\n",
      "step 0 loss: 0.1332830786705017\n",
      "step 20 loss: 0.15568186342716217\n",
      "step 40 loss: 0.1498396396636963\n",
      "step 60 loss: 0.18225282430648804\n",
      "\n",
      "accuracy: 0.81\t auroc:0.8972150749936038\n",
      "use time: 11.670604705810547\n",
      "----------------------------------------\n",
      "epoch: 152\n",
      "step 0 loss: 0.14019636809825897\n",
      "step 20 loss: 0.16777737438678741\n",
      "step 40 loss: 0.1441025733947754\n",
      "step 60 loss: 0.17950357496738434\n",
      "\n",
      "accuracy: 0.834\t auroc:0.8946082809158536\n",
      "use time: 11.667723178863525\n",
      "----------------------------------------\n",
      "epoch: 153\n",
      "step 0 loss: 0.10915137827396393\n",
      "step 20 loss: 0.17980745434761047\n",
      "step 40 loss: 0.1437794268131256\n",
      "step 60 loss: 0.1604057401418686\n",
      "\n",
      "accuracy: 0.834\t auroc:0.9004639127979107\n",
      "use time: 11.657366037368774\n",
      "----------------------------------------\n",
      "epoch: 154\n",
      "step 0 loss: 0.1506587266921997\n",
      "step 20 loss: 0.158911794424057\n",
      "step 40 loss: 0.12542316317558289\n",
      "step 60 loss: 0.20571880042552948\n",
      "\n",
      "accuracy: 0.831\t auroc:0.8951392945242842\n",
      "use time: 11.661881923675537\n",
      "----------------------------------------\n",
      "epoch: 155\n",
      "step 0 loss: 0.10166309773921967\n",
      "step 20 loss: 0.15970478951931\n",
      "step 40 loss: 0.12305321544408798\n",
      "step 60 loss: 0.12991851568222046\n",
      "\n",
      "accuracy: 0.825\t auroc:0.8965199299062037\n",
      "use time: 11.660874843597412\n",
      "----------------------------------------\n",
      "epoch: 156\n",
      "step 0 loss: 0.09879957139492035\n",
      "step 20 loss: 0.15948620438575745\n",
      "step 40 loss: 0.17209240794181824\n",
      "step 60 loss: 0.197238028049469\n",
      "\n",
      "accuracy: 0.835\t auroc:0.8940965768931841\n",
      "use time: 11.681663513183594\n",
      "----------------------------------------\n",
      "epoch: 157\n",
      "step 0 loss: 0.1217675432562828\n",
      "step 20 loss: 0.14329934120178223\n",
      "step 40 loss: 0.14969366788864136\n",
      "step 60 loss: 0.141643688082695\n",
      "\n",
      "accuracy: 0.834\t auroc:0.8957040999077966\n",
      "use time: 11.763802289962769\n",
      "----------------------------------------\n",
      "epoch: 158\n",
      "step 0 loss: 0.10852481424808502\n",
      "step 20 loss: 0.15726956725120544\n",
      "step 40 loss: 0.1202484592795372\n",
      "step 60 loss: 0.21233725547790527\n",
      "\n",
      "accuracy: 0.83\t auroc:0.8982143460567411\n",
      "use time: 11.645625114440918\n",
      "----------------------------------------\n",
      "epoch: 159\n",
      "step 0 loss: 0.09751255810260773\n",
      "step 20 loss: 0.16922134160995483\n",
      "step 40 loss: 0.12636196613311768\n",
      "step 60 loss: 0.20100870728492737\n",
      "\n",
      "accuracy: 0.827\t auroc:0.899392230788169\n",
      "use time: 11.629606246948242\n",
      "----------------------------------------\n",
      "epoch: 160\n",
      "step 0 loss: 0.10266539454460144\n",
      "step 20 loss: 0.16066506505012512\n",
      "step 40 loss: 0.0885619968175888\n",
      "step 60 loss: 0.14904287457466125\n",
      "\n",
      "accuracy: 0.827\t auroc:0.907729144440529\n",
      "use time: 11.566299200057983\n",
      "----------------------------------------\n",
      "epoch: 161\n",
      "step 0 loss: 0.10576722025871277\n",
      "step 20 loss: 0.15181656181812286\n",
      "step 40 loss: 0.13069505989551544\n",
      "step 60 loss: 0.12963715195655823\n",
      "\n",
      "accuracy: 0.826\t auroc:0.8981612446958981\n",
      "use time: 11.606596231460571\n",
      "----------------------------------------\n",
      "epoch: 162\n",
      "step 0 loss: 0.09756845235824585\n",
      "step 20 loss: 0.1668519526720047\n",
      "step 40 loss: 0.13118579983711243\n",
      "step 60 loss: 0.1258254051208496\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9046589203045121\n",
      "use time: 11.668190956115723\n",
      "----------------------------------------\n",
      "epoch: 163\n",
      "step 0 loss: 0.10661210119724274\n",
      "step 20 loss: 0.13337326049804688\n",
      "step 40 loss: 0.1573275327682495\n",
      "step 60 loss: 0.15251798927783966\n",
      "\n",
      "accuracy: 0.821\t auroc:0.8998363512606746\n",
      "use time: 11.637104511260986\n",
      "----------------------------------------\n",
      "epoch: 164\n",
      "step 0 loss: 0.0883646011352539\n",
      "step 20 loss: 0.1699218451976776\n",
      "step 40 loss: 0.12927809357643127\n",
      "step 60 loss: 0.11365435272455215\n",
      "\n",
      "accuracy: 0.832\t auroc:0.8954096287249397\n",
      "use time: 11.6256742477417\n",
      "----------------------------------------\n",
      "epoch: 165\n",
      "step 0 loss: 0.10187037289142609\n",
      "step 20 loss: 0.14023037254810333\n",
      "step 40 loss: 0.15396824479103088\n",
      "step 60 loss: 0.13509124517440796\n",
      "\n",
      "accuracy: 0.825\t auroc:0.9019217865228747\n",
      "use time: 11.562976598739624\n",
      "----------------------------------------\n",
      "epoch: 166\n",
      "step 0 loss: 0.08944636583328247\n",
      "step 20 loss: 0.1501336395740509\n",
      "step 40 loss: 0.12278532236814499\n",
      "step 60 loss: 0.14057713747024536\n",
      "\n",
      "accuracy: 0.835\t auroc:0.8980164228026898\n",
      "use time: 11.593940496444702\n",
      "----------------------------------------\n",
      "epoch: 167\n",
      "step 0 loss: 0.08729684352874756\n",
      "step 20 loss: 0.164326012134552\n",
      "step 40 loss: 0.10873748362064362\n",
      "step 60 loss: 0.13815346360206604\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9037368875844192\n",
      "use time: 11.648244619369507\n",
      "----------------------------------------\n",
      "epoch: 168\n",
      "step 0 loss: 0.13943105936050415\n",
      "step 20 loss: 0.14999425411224365\n",
      "step 40 loss: 0.1523669958114624\n",
      "step 60 loss: 0.14595390856266022\n",
      "\n",
      "accuracy: 0.834\t auroc:0.9020907453982844\n",
      "use time: 11.903780937194824\n",
      "----------------------------------------\n",
      "epoch: 169\n",
      "step 0 loss: 0.1080586165189743\n",
      "step 20 loss: 0.1666700690984726\n",
      "step 40 loss: 0.12216250598430634\n",
      "step 60 loss: 0.16121073067188263\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9017817920261065\n",
      "use time: 11.617156982421875\n",
      "----------------------------------------\n",
      "epoch: 170\n",
      "step 0 loss: 0.0983833447098732\n",
      "step 20 loss: 0.14733687043190002\n",
      "step 40 loss: 0.12567389011383057\n",
      "step 60 loss: 0.16886457800865173\n",
      "\n",
      "accuracy: 0.831\t auroc:0.8979633214418468\n",
      "use time: 11.606552839279175\n",
      "----------------------------------------\n",
      "epoch: 171\n",
      "step 0 loss: 0.12067713588476181\n",
      "step 20 loss: 0.138614222407341\n",
      "step 40 loss: 0.12461690604686737\n",
      "step 60 loss: 0.1353890299797058\n",
      "\n",
      "accuracy: 0.821\t auroc:0.8973454146974912\n",
      "use time: 11.618045330047607\n",
      "----------------------------------------\n",
      "epoch: 172\n",
      "step 0 loss: 0.095527783036232\n",
      "step 20 loss: 0.13956600427627563\n",
      "step 40 loss: 0.1054903119802475\n",
      "step 60 loss: 0.09036573767662048\n",
      "\n",
      "accuracy: 0.834\t auroc:0.8961144286052204\n",
      "use time: 11.639580726623535\n",
      "----------------------------------------\n",
      "epoch: 173\n",
      "step 0 loss: 0.08149614930152893\n",
      "step 20 loss: 0.14515990018844604\n",
      "step 40 loss: 0.1509147435426712\n",
      "step 60 loss: 0.14870432019233704\n",
      "\n",
      "accuracy: 0.826\t auroc:0.9015500769969732\n",
      "use time: 11.643506288528442\n",
      "----------------------------------------\n",
      "epoch: 174\n",
      "step 0 loss: 0.0664299875497818\n",
      "step 20 loss: 0.15552519261837006\n",
      "step 40 loss: 0.11770911514759064\n",
      "step 60 loss: 0.15135811269283295\n",
      "\n",
      "accuracy: 0.831\t auroc:0.9039010190633885\n",
      "use time: 11.581809282302856\n",
      "----------------------------------------\n",
      "epoch: 175\n",
      "step 0 loss: 0.10769196599721909\n",
      "step 20 loss: 0.1040990948677063\n",
      "step 40 loss: 0.12365762889385223\n",
      "step 60 loss: 0.15007713437080383\n",
      "\n",
      "accuracy: 0.828\t auroc:0.9002611621474189\n",
      "use time: 11.533800601959229\n",
      "----------------------------------------\n",
      "epoch: 176\n",
      "step 0 loss: 0.09132599830627441\n",
      "step 20 loss: 0.10997211188077927\n",
      "step 40 loss: 0.12966543436050415\n",
      "step 60 loss: 0.14050322771072388\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9014487016717274\n",
      "use time: 11.572728157043457\n",
      "----------------------------------------\n",
      "epoch: 177\n",
      "step 0 loss: 0.08302387595176697\n",
      "step 20 loss: 0.12799987196922302\n",
      "step 40 loss: 0.1117737889289856\n",
      "step 60 loss: 0.14686301350593567\n",
      "\n",
      "accuracy: 0.838\t auroc:0.900154959425733\n",
      "use time: 11.596182107925415\n",
      "----------------------------------------\n",
      "epoch: 178\n",
      "step 0 loss: 0.08393566310405731\n",
      "step 20 loss: 0.11160887032747269\n",
      "step 40 loss: 0.10149644315242767\n",
      "step 60 loss: 0.12496186047792435\n",
      "\n",
      "accuracy: 0.819\t auroc:0.8873720136518771\n",
      "use time: 11.59624195098877\n",
      "----------------------------------------\n",
      "epoch: 179\n",
      "step 0 loss: 0.08766348659992218\n",
      "step 20 loss: 0.15346553921699524\n",
      "step 40 loss: 0.12496841698884964\n",
      "step 60 loss: 0.1218976378440857\n",
      "\n",
      "accuracy: 0.835\t auroc:0.903249320543951\n",
      "use time: 11.565961837768555\n",
      "----------------------------------------\n",
      "epoch: 180\n",
      "step 0 loss: 0.09835732728242874\n",
      "step 20 loss: 0.12339585274457932\n",
      "step 40 loss: 0.11706358194351196\n",
      "step 60 loss: 0.1308591663837433\n",
      "\n",
      "accuracy: 0.839\t auroc:0.9007052826199246\n",
      "use time: 11.601442575454712\n",
      "----------------------------------------\n",
      "epoch: 181\n",
      "step 0 loss: 0.08523990958929062\n",
      "step 20 loss: 0.14121991395950317\n",
      "step 40 loss: 0.10062843561172485\n",
      "step 60 loss: 0.12482030689716339\n",
      "\n",
      "accuracy: 0.831\t auroc:0.8982336556425023\n",
      "use time: 11.573876142501831\n",
      "----------------------------------------\n",
      "epoch: 182\n",
      "step 0 loss: 0.06961533427238464\n",
      "step 20 loss: 0.13915973901748657\n",
      "step 40 loss: 0.11520987749099731\n",
      "step 60 loss: 0.13428562879562378\n",
      "\n",
      "accuracy: 0.83\t auroc:0.8992763732736024\n",
      "use time: 11.619361162185669\n",
      "----------------------------------------\n",
      "epoch: 183\n",
      "step 0 loss: 0.07953912764787674\n",
      "step 20 loss: 0.13840901851654053\n",
      "step 40 loss: 0.09877659380435944\n",
      "step 60 loss: 0.10945476591587067\n",
      "\n",
      "accuracy: 0.821\t auroc:0.9070629637317705\n",
      "use time: 11.613292217254639\n",
      "----------------------------------------\n",
      "epoch: 184\n",
      "step 0 loss: 0.08710081875324249\n",
      "step 20 loss: 0.14446407556533813\n",
      "step 40 loss: 0.125912144780159\n",
      "step 60 loss: 0.0961579978466034\n",
      "\n",
      "accuracy: 0.831\t auroc:0.9015790413756148\n",
      "use time: 11.569854021072388\n",
      "----------------------------------------\n",
      "epoch: 185\n",
      "step 0 loss: 0.07917051017284393\n",
      "step 20 loss: 0.10324928164482117\n",
      "step 40 loss: 0.12824322283267975\n",
      "step 60 loss: 0.14676041901111603\n",
      "\n",
      "accuracy: 0.833\t auroc:0.906254374828024\n",
      "use time: 11.547324180603027\n",
      "----------------------------------------\n",
      "epoch: 186\n",
      "step 0 loss: 0.06595086306333542\n",
      "step 20 loss: 0.13387486338615417\n",
      "step 40 loss: 0.11102726310491562\n",
      "step 60 loss: 0.1385010927915573\n",
      "\n",
      "accuracy: 0.827\t auroc:0.9020521262267621\n",
      "use time: 11.56096076965332\n",
      "----------------------------------------\n",
      "epoch: 187\n",
      "step 0 loss: 0.07384605705738068\n",
      "step 20 loss: 0.12410035729408264\n",
      "step 40 loss: 0.12960997223854065\n",
      "step 60 loss: 0.13696977496147156\n",
      "\n",
      "accuracy: 0.842\t auroc:0.9001163402542107\n",
      "use time: 11.593565464019775\n",
      "----------------------------------------\n",
      "epoch: 188\n",
      "step 0 loss: 0.0843583196401596\n",
      "step 20 loss: 0.15739913284778595\n",
      "step 40 loss: 0.08216212689876556\n",
      "step 60 loss: 0.14529144763946533\n",
      "\n",
      "accuracy: 0.838\t auroc:0.9005459785373955\n",
      "use time: 11.561456680297852\n",
      "----------------------------------------\n",
      "epoch: 189\n",
      "step 0 loss: 0.09639793634414673\n",
      "step 20 loss: 0.13916057348251343\n",
      "step 40 loss: 0.08822406828403473\n",
      "step 60 loss: 0.1405077576637268\n",
      "\n",
      "accuracy: 0.838\t auroc:0.905595435213926\n",
      "use time: 11.599900484085083\n",
      "----------------------------------------\n",
      "epoch: 190\n",
      "step 0 loss: 0.05831544101238251\n",
      "step 20 loss: 0.09976518154144287\n",
      "step 40 loss: 0.09147967398166656\n",
      "step 60 loss: 0.16752547025680542\n",
      "\n",
      "accuracy: 0.823\t auroc:0.892252511452998\n",
      "use time: 11.952452182769775\n",
      "----------------------------------------\n",
      "epoch: 191\n",
      "step 0 loss: 0.07062044739723206\n",
      "step 20 loss: 0.12976451218128204\n",
      "step 40 loss: 0.10392875224351883\n",
      "step 60 loss: 0.13428397476673126\n",
      "\n",
      "accuracy: 0.842\t auroc:0.9066140158628246\n",
      "use time: 11.566656112670898\n",
      "----------------------------------------\n",
      "epoch: 192\n",
      "step 0 loss: 0.0726562961935997\n",
      "step 20 loss: 0.08262279629707336\n",
      "step 40 loss: 0.08882862329483032\n",
      "step 60 loss: 0.10561126470565796\n",
      "\n",
      "accuracy: 0.838\t auroc:0.9046782298902734\n",
      "use time: 11.554548263549805\n",
      "----------------------------------------\n",
      "epoch: 193\n",
      "step 0 loss: 0.06846757978200912\n",
      "step 20 loss: 0.10818446427583694\n",
      "step 40 loss: 0.0789206326007843\n",
      "step 60 loss: 0.09088199585676193\n",
      "\n",
      "accuracy: 0.842\t auroc:0.9022355672914926\n",
      "use time: 11.603538274765015\n",
      "----------------------------------------\n",
      "epoch: 194\n",
      "step 0 loss: 0.08683783560991287\n",
      "step 20 loss: 0.12281312048435211\n",
      "step 40 loss: 0.09114979952573776\n",
      "step 60 loss: 0.07786771655082703\n",
      "\n",
      "accuracy: 0.83\t auroc:0.9041954902462453\n",
      "use time: 11.57474946975708\n",
      "----------------------------------------\n",
      "epoch: 195\n",
      "step 0 loss: 0.074371837079525\n",
      "step 20 loss: 0.10893963277339935\n",
      "step 40 loss: 0.12233241647481918\n",
      "step 60 loss: 0.14781878888607025\n",
      "\n",
      "accuracy: 0.838\t auroc:0.9054457859242774\n",
      "use time: 11.536409616470337\n",
      "----------------------------------------\n",
      "epoch: 196\n",
      "step 0 loss: 0.08171289414167404\n",
      "step 20 loss: 0.11424801498651505\n",
      "step 40 loss: 0.08867620676755905\n",
      "step 60 loss: 0.10759356617927551\n",
      "\n",
      "accuracy: 0.829\t auroc:0.9036403396556134\n",
      "use time: 11.563021183013916\n",
      "----------------------------------------\n",
      "epoch: 197\n",
      "step 0 loss: 0.07092928886413574\n",
      "step 20 loss: 0.12195621430873871\n",
      "step 40 loss: 0.09669274091720581\n",
      "step 60 loss: 0.15958991646766663\n",
      "\n",
      "accuracy: 0.839\t auroc:0.9015693865827343\n",
      "use time: 11.567226886749268\n",
      "----------------------------------------\n",
      "epoch: 198\n",
      "step 0 loss: 0.07860877364873886\n",
      "step 20 loss: 0.07265287637710571\n",
      "step 40 loss: 0.06799331307411194\n",
      "step 60 loss: 0.11669617146253586\n",
      "\n",
      "accuracy: 0.836\t auroc:0.8973454146974911\n",
      "use time: 11.556780099868774\n",
      "----------------------------------------\n",
      "epoch: 199\n",
      "step 0 loss: 0.08018788695335388\n",
      "step 20 loss: 0.10272243618965149\n",
      "step 40 loss: 0.09105793386697769\n",
      "step 60 loss: 0.13424313068389893\n",
      "\n",
      "accuracy: 0.84\t auroc:0.9044899614291024\n",
      "use time: 11.546332359313965\n",
      "----------------------------------------\n",
      "epoch: 200\n",
      "step 0 loss: 0.08037736266851425\n",
      "step 20 loss: 0.12079495936632156\n",
      "step 40 loss: 0.12422063946723938\n",
      "step 60 loss: 0.11678779125213623\n",
      "\n",
      "accuracy: 0.844\t auroc:0.9057209475213732\n",
      "use time: 11.55644702911377\n",
      "----------------------------------------\n",
      "epoch: 201\n",
      "step 0 loss: 0.06765374541282654\n",
      "step 20 loss: 0.10836492478847504\n",
      "step 40 loss: 0.07759743183851242\n",
      "step 60 loss: 0.14388194680213928\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9052237256880248\n",
      "use time: 11.525751829147339\n",
      "----------------------------------------\n",
      "epoch: 202\n",
      "step 0 loss: 0.07776768505573273\n",
      "step 20 loss: 0.09808510541915894\n",
      "step 40 loss: 0.0623292401432991\n",
      "step 60 loss: 0.11263683438301086\n",
      "\n",
      "accuracy: 0.842\t auroc:0.9052961366346288\n",
      "use time: 11.574619054794312\n",
      "----------------------------------------\n",
      "epoch: 203\n",
      "step 0 loss: 0.0541602224111557\n",
      "step 20 loss: 0.09890332072973251\n",
      "step 40 loss: 0.10737321525812149\n",
      "step 60 loss: 0.10109181702136993\n",
      "\n",
      "accuracy: 0.834\t auroc:0.8994501595454523\n",
      "use time: 11.522195100784302\n",
      "----------------------------------------\n",
      "epoch: 204\n",
      "step 0 loss: 0.07479451596736908\n",
      "step 20 loss: 0.11649944633245468\n",
      "step 40 loss: 0.07000988721847534\n",
      "step 60 loss: 0.1288348287343979\n",
      "\n",
      "accuracy: 0.83\t auroc:0.8968868120356647\n",
      "use time: 11.524266958236694\n",
      "----------------------------------------\n",
      "epoch: 205\n",
      "step 0 loss: 0.04909884184598923\n",
      "step 20 loss: 0.11805172264575958\n",
      "step 40 loss: 0.1170937716960907\n",
      "step 60 loss: 0.11340579390525818\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9017528276474649\n",
      "use time: 11.52994990348816\n",
      "----------------------------------------\n",
      "epoch: 206\n",
      "step 0 loss: 0.08535486459732056\n",
      "step 20 loss: 0.11832665652036667\n",
      "step 40 loss: 0.11234398186206818\n",
      "step 60 loss: 0.07356865704059601\n",
      "\n",
      "accuracy: 0.837\t auroc:0.8992329267056399\n",
      "use time: 11.676299333572388\n",
      "----------------------------------------\n",
      "epoch: 207\n",
      "step 0 loss: 0.05317896232008934\n",
      "step 20 loss: 0.11409839242696762\n",
      "step 40 loss: 0.08972691744565964\n",
      "step 60 loss: 0.08017288893461227\n",
      "\n",
      "accuracy: 0.847\t auroc:0.9054264763385164\n",
      "use time: 11.561643600463867\n",
      "----------------------------------------\n",
      "epoch: 208\n",
      "step 0 loss: 0.055208273231983185\n",
      "step 20 loss: 0.1224200427532196\n",
      "step 40 loss: 0.0899505764245987\n",
      "step 60 loss: 0.09271523356437683\n",
      "\n",
      "accuracy: 0.832\t auroc:0.9024383179419843\n",
      "use time: 11.58948826789856\n",
      "----------------------------------------\n",
      "epoch: 209\n",
      "step 0 loss: 0.0645885244011879\n",
      "step 20 loss: 0.10005687177181244\n",
      "step 40 loss: 0.05931512266397476\n",
      "step 60 loss: 0.1125122681260109\n",
      "\n",
      "accuracy: 0.832\t auroc:0.8999135896037191\n",
      "use time: 11.603053331375122\n",
      "----------------------------------------\n",
      "epoch: 210\n",
      "step 0 loss: 0.0733431950211525\n",
      "step 20 loss: 0.08609139919281006\n",
      "step 40 loss: 0.07092642039060593\n",
      "step 60 loss: 0.10398750752210617\n",
      "\n",
      "accuracy: 0.831\t auroc:0.9019121317299941\n",
      "use time: 11.647018194198608\n",
      "----------------------------------------\n",
      "epoch: 211\n",
      "step 0 loss: 0.049897730350494385\n",
      "step 20 loss: 0.10142655670642853\n",
      "step 40 loss: 0.11950980126857758\n",
      "step 60 loss: 0.10536372661590576\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9039637752171121\n",
      "use time: 11.684705257415771\n",
      "----------------------------------------\n",
      "epoch: 212\n",
      "step 0 loss: 0.050943080335855484\n",
      "step 20 loss: 0.12790022790431976\n",
      "step 40 loss: 0.07408323884010315\n",
      "step 60 loss: 0.0898289754986763\n",
      "\n",
      "accuracy: 0.839\t auroc:0.9043161751572525\n",
      "use time: 11.69516110420227\n",
      "----------------------------------------\n",
      "epoch: 213\n",
      "step 0 loss: 0.08536884933710098\n",
      "step 20 loss: 0.10604910552501678\n",
      "step 40 loss: 0.07680021971464157\n",
      "step 60 loss: 0.10046163201332092\n",
      "\n",
      "accuracy: 0.832\t auroc:0.9021631563448885\n",
      "use time: 11.594630479812622\n",
      "----------------------------------------\n",
      "epoch: 214\n",
      "step 0 loss: 0.044290900230407715\n",
      "step 20 loss: 0.09003879874944687\n",
      "step 40 loss: 0.06587047874927521\n",
      "step 60 loss: 0.11586232483386993\n",
      "\n",
      "accuracy: 0.84\t auroc:0.905160969534301\n",
      "use time: 12.030973196029663\n",
      "----------------------------------------\n",
      "epoch: 215\n",
      "step 0 loss: 0.05433417856693268\n",
      "step 20 loss: 0.11064138263463974\n",
      "step 40 loss: 0.08427421748638153\n",
      "step 60 loss: 0.09622027724981308\n",
      "\n",
      "accuracy: 0.834\t auroc:0.9009852716134606\n",
      "use time: 11.628610372543335\n",
      "----------------------------------------\n",
      "epoch: 216\n",
      "step 0 loss: 0.044305719435214996\n",
      "step 20 loss: 0.10909958183765411\n",
      "step 40 loss: 0.093378446996212\n",
      "step 60 loss: 0.14124232530593872\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9053733749776733\n",
      "use time: 11.66672396659851\n",
      "----------------------------------------\n",
      "epoch: 217\n",
      "step 0 loss: 0.07919996231794357\n",
      "step 20 loss: 0.06005505472421646\n",
      "step 40 loss: 0.08253208547830582\n",
      "step 60 loss: 0.06158971041440964\n",
      "\n",
      "accuracy: 0.83\t auroc:0.9011831948675121\n",
      "use time: 11.591642618179321\n",
      "----------------------------------------\n",
      "epoch: 218\n",
      "step 0 loss: 0.0708947479724884\n",
      "step 20 loss: 0.07870005071163177\n",
      "step 40 loss: 0.07431864738464355\n",
      "step 60 loss: 0.12283198535442352\n",
      "\n",
      "accuracy: 0.84\t auroc:0.8968433654677022\n",
      "use time: 11.563615798950195\n",
      "----------------------------------------\n",
      "epoch: 219\n",
      "step 0 loss: 0.04173099622130394\n",
      "step 20 loss: 0.12399275600910187\n",
      "step 40 loss: 0.08128046989440918\n",
      "step 60 loss: 0.07853671908378601\n",
      "\n",
      "accuracy: 0.833\t auroc:0.8931262702086883\n",
      "use time: 11.565253496170044\n",
      "----------------------------------------\n",
      "epoch: 220\n",
      "step 0 loss: 0.038940589874982834\n",
      "step 20 loss: 0.11321929097175598\n",
      "step 40 loss: 0.05162700265645981\n",
      "step 60 loss: 0.0866490975022316\n",
      "\n",
      "accuracy: 0.83\t auroc:0.9034906903659649\n",
      "use time: 11.59324312210083\n",
      "----------------------------------------\n",
      "epoch: 221\n",
      "step 0 loss: 0.07402713596820831\n",
      "step 20 loss: 0.1073032021522522\n",
      "step 40 loss: 0.09159146249294281\n",
      "step 60 loss: 0.08821748197078705\n",
      "\n",
      "accuracy: 0.836\t auroc:0.8989046637477008\n",
      "use time: 11.551937818527222\n",
      "----------------------------------------\n",
      "epoch: 222\n",
      "step 0 loss: 0.05155676230788231\n",
      "step 20 loss: 0.08937041461467743\n",
      "step 40 loss: 0.08364368230104446\n",
      "step 60 loss: 0.12501269578933716\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8989963842800662\n",
      "use time: 11.635289430618286\n",
      "----------------------------------------\n",
      "epoch: 223\n",
      "step 0 loss: 0.06604640185832977\n",
      "step 20 loss: 0.05978969484567642\n",
      "step 40 loss: 0.06028372794389725\n",
      "step 60 loss: 0.08427954465150833\n",
      "\n",
      "accuracy: 0.834\t auroc:0.9032927671119135\n",
      "use time: 11.637206792831421\n",
      "----------------------------------------\n",
      "epoch: 224\n",
      "step 0 loss: 0.07140078395605087\n",
      "step 20 loss: 0.07449623197317123\n",
      "step 40 loss: 0.06984023004770279\n",
      "step 60 loss: 0.06276324391365051\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9033120766976747\n",
      "use time: 11.616498470306396\n",
      "----------------------------------------\n",
      "epoch: 225\n",
      "step 0 loss: 0.088121198117733\n",
      "step 20 loss: 0.07509128004312515\n",
      "step 40 loss: 0.07690568268299103\n",
      "step 60 loss: 0.07665091753005981\n",
      "\n",
      "accuracy: 0.828\t auroc:0.9005411511409551\n",
      "use time: 11.597406387329102\n",
      "----------------------------------------\n",
      "epoch: 226\n",
      "step 0 loss: 0.05565460026264191\n",
      "step 20 loss: 0.0476471483707428\n",
      "step 40 loss: 0.0623234324157238\n",
      "step 60 loss: 0.06402528285980225\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8966792339887328\n",
      "use time: 11.665010452270508\n",
      "----------------------------------------\n",
      "epoch: 227\n",
      "step 0 loss: 0.036372486501932144\n",
      "step 20 loss: 0.09577184170484543\n",
      "step 40 loss: 0.09088866412639618\n",
      "step 60 loss: 0.08966811001300812\n",
      "\n",
      "accuracy: 0.824\t auroc:0.9036934410164567\n",
      "use time: 11.663240671157837\n",
      "----------------------------------------\n",
      "epoch: 228\n",
      "step 0 loss: 0.056560128927230835\n",
      "step 20 loss: 0.07090941071510315\n",
      "step 40 loss: 0.07717856764793396\n",
      "step 60 loss: 0.08132424205541611\n",
      "\n",
      "accuracy: 0.844\t auroc:0.9020038522623594\n",
      "use time: 11.619818210601807\n",
      "----------------------------------------\n",
      "epoch: 229\n",
      "step 0 loss: 0.07996487617492676\n",
      "step 20 loss: 0.06392206996679306\n",
      "step 40 loss: 0.03913571313023567\n",
      "step 60 loss: 0.09344065189361572\n",
      "\n",
      "accuracy: 0.835\t auroc:0.9019217865228746\n",
      "use time: 11.60761308670044\n",
      "----------------------------------------\n",
      "epoch: 230\n",
      "step 0 loss: 0.05978940799832344\n",
      "step 20 loss: 0.10391557961702347\n",
      "step 40 loss: 0.07396866381168365\n",
      "step 60 loss: 0.10930515080690384\n",
      "\n",
      "accuracy: 0.831\t auroc:0.8993970581846092\n",
      "use time: 11.641510248184204\n",
      "----------------------------------------\n",
      "epoch: 231\n",
      "step 0 loss: 0.05675991624593735\n",
      "step 20 loss: 0.09792235493659973\n",
      "step 40 loss: 0.061141952872276306\n",
      "step 60 loss: 0.12417758256196976\n",
      "\n",
      "accuracy: 0.84\t auroc:0.9045671997721468\n",
      "use time: 11.647545337677002\n",
      "----------------------------------------\n",
      "epoch: 232\n",
      "step 0 loss: 0.05175100266933441\n",
      "step 20 loss: 0.10027475655078888\n",
      "step 40 loss: 0.09902983158826828\n",
      "step 60 loss: 0.06505236029624939\n",
      "\n",
      "accuracy: 0.827\t auroc:0.9005990798982384\n",
      "use time: 11.656063795089722\n",
      "----------------------------------------\n",
      "epoch: 233\n",
      "step 0 loss: 0.056524429470300674\n",
      "step 20 loss: 0.07581088691949844\n",
      "step 40 loss: 0.04743054509162903\n",
      "step 60 loss: 0.06804366409778595\n",
      "\n",
      "accuracy: 0.829\t auroc:0.9006087346911191\n",
      "use time: 11.785551309585571\n",
      "----------------------------------------\n",
      "epoch: 234\n",
      "step 0 loss: 0.060421161353588104\n",
      "step 20 loss: 0.08211469650268555\n",
      "step 40 loss: 0.09827357530593872\n",
      "step 60 loss: 0.06538412719964981\n",
      "\n",
      "accuracy: 0.835\t auroc:0.9010118222938822\n",
      "use time: 11.622742176055908\n",
      "----------------------------------------\n",
      "epoch: 235\n",
      "step 0 loss: 0.04316335916519165\n",
      "step 20 loss: 0.08449877798557281\n",
      "step 40 loss: 0.06167382001876831\n",
      "step 60 loss: 0.11347086727619171\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9050354572268539\n",
      "use time: 11.669876337051392\n",
      "----------------------------------------\n",
      "epoch: 236\n",
      "step 0 loss: 0.05406070500612259\n",
      "step 20 loss: 0.07126887142658234\n",
      "step 40 loss: 0.06557942926883698\n",
      "step 60 loss: 0.08638188987970352\n",
      "\n",
      "accuracy: 0.839\t auroc:0.9055568160424038\n",
      "use time: 11.750929832458496\n",
      "----------------------------------------\n",
      "epoch: 237\n",
      "step 0 loss: 0.053584493696689606\n",
      "step 20 loss: 0.08320635557174683\n",
      "step 40 loss: 0.05010842904448509\n",
      "step 60 loss: 0.09397406131029129\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9000294471182857\n",
      "use time: 11.670578479766846\n",
      "----------------------------------------\n",
      "epoch: 238\n",
      "step 0 loss: 0.06622776389122009\n",
      "step 20 loss: 0.07072047889232635\n",
      "step 40 loss: 0.09648298472166061\n",
      "step 60 loss: 0.08371143788099289\n",
      "\n",
      "accuracy: 0.834\t auroc:0.8975288557622216\n",
      "use time: 11.700746536254883\n",
      "----------------------------------------\n",
      "epoch: 239\n",
      "step 0 loss: 0.06732101738452911\n",
      "step 20 loss: 0.049619246274232864\n",
      "step 40 loss: 0.08875381946563721\n",
      "step 60 loss: 0.09235458821058273\n",
      "\n",
      "accuracy: 0.839\t auroc:0.8965488942848454\n",
      "use time: 11.684202671051025\n",
      "----------------------------------------\n",
      "epoch: 240\n",
      "step 0 loss: 0.07061207294464111\n",
      "step 20 loss: 0.08901488780975342\n",
      "step 40 loss: 0.06863103806972504\n",
      "step 60 loss: 0.09114816039800644\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9059188707754247\n",
      "use time: 12.10191297531128\n",
      "----------------------------------------\n",
      "epoch: 241\n",
      "step 0 loss: 0.05790453776717186\n",
      "step 20 loss: 0.08738672733306885\n",
      "step 40 loss: 0.05259301885962486\n",
      "step 60 loss: 0.06408914923667908\n",
      "\n",
      "accuracy: 0.828\t auroc:0.8985088172395982\n",
      "use time: 11.683814764022827\n",
      "----------------------------------------\n",
      "epoch: 242\n",
      "step 0 loss: 0.04535005986690521\n",
      "step 20 loss: 0.08101586997509003\n",
      "step 40 loss: 0.06254802644252777\n",
      "step 60 loss: 0.06270825117826462\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8966599244029717\n",
      "use time: 11.67342472076416\n",
      "----------------------------------------\n",
      "epoch: 243\n",
      "step 0 loss: 0.034988999366760254\n",
      "step 20 loss: 0.09790602326393127\n",
      "step 40 loss: 0.062138646841049194\n",
      "step 60 loss: 0.04899095743894577\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9039927395957538\n",
      "use time: 11.686405181884766\n",
      "----------------------------------------\n",
      "epoch: 244\n",
      "step 0 loss: 0.04342476278543472\n",
      "step 20 loss: 0.05156064033508301\n",
      "step 40 loss: 0.056644849479198456\n",
      "step 60 loss: 0.06720466911792755\n",
      "\n",
      "accuracy: 0.833\t auroc:0.8984170967072329\n",
      "use time: 11.704811573028564\n",
      "----------------------------------------\n",
      "epoch: 245\n",
      "step 0 loss: 0.04830411821603775\n",
      "step 20 loss: 0.07714629918336868\n",
      "step 40 loss: 0.0678202211856842\n",
      "step 60 loss: 0.08125531673431396\n",
      "\n",
      "accuracy: 0.833\t auroc:0.8999763457574426\n",
      "use time: 11.718093156814575\n",
      "----------------------------------------\n",
      "epoch: 246\n",
      "step 0 loss: 0.04899757355451584\n",
      "step 20 loss: 0.04506902024149895\n",
      "step 40 loss: 0.06670769304037094\n",
      "step 60 loss: 0.08497616648674011\n",
      "\n",
      "accuracy: 0.83\t auroc:0.9005797703124774\n",
      "use time: 11.75715446472168\n",
      "----------------------------------------\n",
      "epoch: 247\n",
      "step 0 loss: 0.04252363741397858\n",
      "step 20 loss: 0.07815796136856079\n",
      "step 40 loss: 0.09295304119586945\n",
      "step 60 loss: 0.0772605687379837\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9043258299501329\n",
      "use time: 11.842849731445312\n",
      "----------------------------------------\n",
      "epoch: 248\n",
      "step 0 loss: 0.04293767362833023\n",
      "step 20 loss: 0.06753246486186981\n",
      "step 40 loss: 0.05683765560388565\n",
      "step 60 loss: 0.0468377023935318\n",
      "\n",
      "accuracy: 0.83\t auroc:0.9039879121993135\n",
      "use time: 11.738386869430542\n",
      "----------------------------------------\n",
      "epoch: 249\n",
      "step 0 loss: 0.040372107177972794\n",
      "step 20 loss: 0.10078626871109009\n",
      "step 40 loss: 0.07661280035972595\n",
      "step 60 loss: 0.06840673089027405\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9023803891847011\n",
      "use time: 11.691611766815186\n",
      "----------------------------------------\n",
      "epoch: 250\n",
      "step 0 loss: 0.028732314705848694\n",
      "step 20 loss: 0.07913421839475632\n",
      "step 40 loss: 0.10921454429626465\n",
      "step 60 loss: 0.10022982209920883\n",
      "\n",
      "accuracy: 0.847\t auroc:0.9057402571071344\n",
      "use time: 11.699028015136719\n",
      "----------------------------------------\n",
      "epoch: 251\n",
      "step 0 loss: 0.0326431579887867\n",
      "step 20 loss: 0.07316708564758301\n",
      "step 40 loss: 0.08255387842655182\n",
      "step 60 loss: 0.047891609370708466\n",
      "\n",
      "accuracy: 0.83\t auroc:0.9029065753966913\n",
      "use time: 11.697371006011963\n",
      "----------------------------------------\n",
      "epoch: 252\n",
      "step 0 loss: 0.08975981175899506\n",
      "step 20 loss: 0.07382465898990631\n",
      "step 40 loss: 0.04473189264535904\n",
      "step 60 loss: 0.08019806444644928\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9026700329711176\n",
      "use time: 11.691518783569336\n",
      "----------------------------------------\n",
      "epoch: 253\n",
      "step 0 loss: 0.04051731526851654\n",
      "step 20 loss: 0.05835255980491638\n",
      "step 40 loss: 0.05696897953748703\n",
      "step 60 loss: 0.03983019292354584\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9047554682333177\n",
      "use time: 11.725274801254272\n",
      "----------------------------------------\n",
      "epoch: 254\n",
      "step 0 loss: 0.05442797392606735\n",
      "step 20 loss: 0.033834315836429596\n",
      "step 40 loss: 0.0511610209941864\n",
      "step 60 loss: 0.05253073200583458\n",
      "\n",
      "accuracy: 0.826\t auroc:0.9024793508117266\n",
      "use time: 11.680221319198608\n",
      "----------------------------------------\n",
      "epoch: 255\n",
      "step 0 loss: 0.09302651882171631\n",
      "step 20 loss: 0.03712507337331772\n",
      "step 40 loss: 0.06214316189289093\n",
      "step 60 loss: 0.05978512391448021\n",
      "\n",
      "accuracy: 0.838\t auroc:0.9059671447398274\n",
      "use time: 11.747225522994995\n",
      "----------------------------------------\n",
      "epoch: 256\n",
      "step 0 loss: 0.039239708334207535\n",
      "step 20 loss: 0.0672430694103241\n",
      "step 40 loss: 0.06226012855768204\n",
      "step 60 loss: 0.03457535803318024\n",
      "\n",
      "accuracy: 0.834\t auroc:0.9033458684727567\n",
      "use time: 11.733898639678955\n",
      "----------------------------------------\n",
      "epoch: 257\n",
      "step 0 loss: 0.05216856673359871\n",
      "step 20 loss: 0.07289936393499374\n",
      "step 40 loss: 0.04385876655578613\n",
      "step 60 loss: 0.0735974982380867\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9023345289185183\n",
      "use time: 11.785471200942993\n",
      "----------------------------------------\n",
      "epoch: 258\n",
      "step 0 loss: 0.021408550441265106\n",
      "step 20 loss: 0.05026782304048538\n",
      "step 40 loss: 0.06275831907987595\n",
      "step 60 loss: 0.044830359518527985\n",
      "\n",
      "accuracy: 0.83\t auroc:0.9002515073545385\n",
      "use time: 12.653391599655151\n",
      "----------------------------------------\n",
      "epoch: 259\n",
      "step 0 loss: 0.034498535096645355\n",
      "step 20 loss: 0.04574190452694893\n",
      "step 40 loss: 0.06516653299331665\n",
      "step 60 loss: 0.07218265533447266\n",
      "\n",
      "accuracy: 0.837\t auroc:0.90687952266704\n",
      "use time: 11.684165716171265\n",
      "----------------------------------------\n",
      "epoch: 260\n",
      "step 0 loss: 0.054554615169763565\n",
      "step 20 loss: 0.07006525993347168\n",
      "step 40 loss: 0.08413620293140411\n",
      "step 60 loss: 0.06616281718015671\n",
      "\n",
      "accuracy: 0.826\t auroc:0.9031479452187051\n",
      "use time: 11.693986892700195\n",
      "----------------------------------------\n",
      "epoch: 261\n",
      "step 0 loss: 0.0657186359167099\n",
      "step 20 loss: 0.06810930371284485\n",
      "step 40 loss: 0.04861542582511902\n",
      "step 60 loss: 0.07405851781368256\n",
      "\n",
      "accuracy: 0.83\t auroc:0.8963316614450327\n",
      "use time: 11.720998287200928\n",
      "----------------------------------------\n",
      "epoch: 262\n",
      "step 0 loss: 0.03414005786180496\n",
      "step 20 loss: 0.07089494168758392\n",
      "step 40 loss: 0.05742902308702469\n",
      "step 60 loss: 0.06648901849985123\n",
      "\n",
      "accuracy: 0.823\t auroc:0.8986198473577246\n",
      "use time: 11.673580646514893\n",
      "----------------------------------------\n",
      "epoch: 263\n",
      "step 0 loss: 0.036308322101831436\n",
      "step 20 loss: 0.06752615422010422\n",
      "step 40 loss: 0.07273123413324356\n",
      "step 60 loss: 0.04892685264348984\n",
      "\n",
      "accuracy: 0.827\t auroc:0.8996191184208622\n",
      "use time: 11.680896759033203\n",
      "----------------------------------------\n",
      "epoch: 264\n",
      "step 0 loss: 0.07001819461584091\n",
      "step 20 loss: 0.08461479842662811\n",
      "step 40 loss: 0.08248568326234818\n",
      "step 60 loss: 0.06499640643596649\n",
      "\n",
      "accuracy: 0.83\t auroc:0.899150860966155\n",
      "use time: 11.657286405563354\n",
      "----------------------------------------\n",
      "epoch: 265\n",
      "step 0 loss: 0.04262230545282364\n",
      "step 20 loss: 0.043038465082645416\n",
      "step 40 loss: 0.03664906695485115\n",
      "step 60 loss: 0.0906732827425003\n",
      "\n",
      "accuracy: 0.814\t auroc:0.8959020231618481\n",
      "use time: 11.726083517074585\n",
      "----------------------------------------\n",
      "epoch: 266\n",
      "step 0 loss: 0.0591772198677063\n",
      "step 20 loss: 0.060796018689870834\n",
      "step 40 loss: 0.03917578607797623\n",
      "step 60 loss: 0.06915182620286942\n",
      "\n",
      "accuracy: 0.838\t auroc:0.9005097730640934\n",
      "use time: 11.661761045455933\n",
      "----------------------------------------\n",
      "epoch: 267\n",
      "step 0 loss: 0.041316114366054535\n",
      "step 20 loss: 0.059804126620292664\n",
      "step 40 loss: 0.06470227241516113\n",
      "step 60 loss: 0.023305177688598633\n",
      "\n",
      "accuracy: 0.831\t auroc:0.9004252936263885\n",
      "use time: 11.706526279449463\n",
      "----------------------------------------\n",
      "epoch: 268\n",
      "step 0 loss: 0.07088913023471832\n",
      "step 20 loss: 0.05942878872156143\n",
      "step 40 loss: 0.04018518328666687\n",
      "step 60 loss: 0.07134981453418732\n",
      "\n",
      "accuracy: 0.835\t auroc:0.9025831398351927\n",
      "use time: 11.656580448150635\n",
      "----------------------------------------\n",
      "epoch: 269\n",
      "step 0 loss: 0.022480927407741547\n",
      "step 20 loss: 0.04553289711475372\n",
      "step 40 loss: 0.06858869642019272\n",
      "step 60 loss: 0.03221879526972771\n",
      "\n",
      "accuracy: 0.837\t auroc:0.8999184170001593\n",
      "use time: 12.12887954711914\n",
      "----------------------------------------\n",
      "epoch: 270\n",
      "step 0 loss: 0.045284856110811234\n",
      "step 20 loss: 0.03967611491680145\n",
      "step 40 loss: 0.048072151839733124\n",
      "step 60 loss: 0.035775117576122284\n",
      "\n",
      "accuracy: 0.826\t auroc:0.9044899614291024\n",
      "use time: 11.679804801940918\n",
      "----------------------------------------\n",
      "epoch: 271\n",
      "step 0 loss: 0.019220571964979172\n",
      "step 20 loss: 0.06573282927274704\n",
      "step 40 loss: 0.08967413008213043\n",
      "step 60 loss: 0.04478604346513748\n",
      "\n",
      "accuracy: 0.83\t auroc:0.904707194268915\n",
      "use time: 11.660771131515503\n",
      "----------------------------------------\n",
      "epoch: 272\n",
      "step 0 loss: 0.05301157385110855\n",
      "step 20 loss: 0.06898888945579529\n",
      "step 40 loss: 0.04348639026284218\n",
      "step 60 loss: 0.07154688239097595\n",
      "\n",
      "accuracy: 0.835\t auroc:0.8954241109142606\n",
      "use time: 11.724650621414185\n",
      "----------------------------------------\n",
      "epoch: 273\n",
      "step 0 loss: 0.048132896423339844\n",
      "step 20 loss: 0.03614334762096405\n",
      "step 40 loss: 0.03166453167796135\n",
      "step 60 loss: 0.033014629036188126\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9031817369937871\n",
      "use time: 11.67018437385559\n",
      "----------------------------------------\n",
      "epoch: 274\n",
      "step 0 loss: 0.03772759437561035\n",
      "step 20 loss: 0.05850604921579361\n",
      "step 40 loss: 0.039354268461465836\n",
      "step 60 loss: 0.06729605048894882\n",
      "\n",
      "accuracy: 0.826\t auroc:0.9010769921458259\n",
      "use time: 11.646573305130005\n",
      "----------------------------------------\n",
      "epoch: 275\n",
      "step 0 loss: 0.030009429901838303\n",
      "step 20 loss: 0.0856596827507019\n",
      "step 40 loss: 0.02744104713201523\n",
      "step 60 loss: 0.04396672546863556\n",
      "\n",
      "accuracy: 0.835\t auroc:0.9037465423772998\n",
      "use time: 11.663026094436646\n",
      "----------------------------------------\n",
      "epoch: 276\n",
      "step 0 loss: 0.015317913144826889\n",
      "step 20 loss: 0.05858047306537628\n",
      "step 40 loss: 0.03979969024658203\n",
      "step 60 loss: 0.04041337966918945\n",
      "\n",
      "accuracy: 0.833\t auroc:0.8994839513205343\n",
      "use time: 11.649401903152466\n",
      "----------------------------------------\n",
      "epoch: 277\n",
      "step 0 loss: 0.04685375839471817\n",
      "step 20 loss: 0.05927673354744911\n",
      "step 40 loss: 0.06420331448316574\n",
      "step 60 loss: 0.06386671960353851\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9001404772364121\n",
      "use time: 11.700451135635376\n",
      "----------------------------------------\n",
      "epoch: 278\n",
      "step 0 loss: 0.05832570791244507\n",
      "step 20 loss: 0.06662341207265854\n",
      "step 40 loss: 0.08699066936969757\n",
      "step 60 loss: 0.05647580698132515\n",
      "\n",
      "accuracy: 0.839\t auroc:0.9031527726151455\n",
      "use time: 11.641154289245605\n",
      "----------------------------------------\n",
      "epoch: 279\n",
      "step 0 loss: 0.0340886153280735\n",
      "step 20 loss: 0.0587422177195549\n",
      "step 40 loss: 0.04982057958841324\n",
      "step 60 loss: 0.05064259469509125\n",
      "\n",
      "accuracy: 0.834\t auroc:0.9039348108384705\n",
      "use time: 11.611160516738892\n",
      "----------------------------------------\n",
      "epoch: 280\n",
      "step 0 loss: 0.04905400425195694\n",
      "step 20 loss: 0.056276656687259674\n",
      "step 40 loss: 0.032589465379714966\n",
      "step 60 loss: 0.08567911386489868\n",
      "\n",
      "accuracy: 0.831\t auroc:0.9017817920261065\n",
      "use time: 11.67555832862854\n",
      "----------------------------------------\n",
      "epoch: 281\n",
      "step 0 loss: 0.034199103713035583\n",
      "step 20 loss: 0.052372269332408905\n",
      "step 40 loss: 0.05084555968642235\n",
      "step 60 loss: 0.031932052224874496\n",
      "\n",
      "accuracy: 0.842\t auroc:0.9053251010132706\n",
      "use time: 11.652710199356079\n",
      "----------------------------------------\n",
      "epoch: 282\n",
      "step 0 loss: 0.02999264933168888\n",
      "step 20 loss: 0.05321758985519409\n",
      "step 40 loss: 0.025451138615608215\n",
      "step 60 loss: 0.07709707319736481\n",
      "\n",
      "accuracy: 0.824\t auroc:0.9013087071749594\n",
      "use time: 11.69469952583313\n",
      "----------------------------------------\n",
      "epoch: 283\n",
      "step 0 loss: 0.022058002650737762\n",
      "step 20 loss: 0.06505107879638672\n",
      "step 40 loss: 0.043950267136096954\n",
      "step 60 loss: 0.047661736607551575\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9045720271685871\n",
      "use time: 11.66888165473938\n",
      "----------------------------------------\n",
      "epoch: 284\n",
      "step 0 loss: 0.03630134463310242\n",
      "step 20 loss: 0.05347266048192978\n",
      "step 40 loss: 0.06186128407716751\n",
      "step 60 loss: 0.05381546914577484\n",
      "\n",
      "accuracy: 0.839\t auroc:0.9039203286491497\n",
      "use time: 11.693329334259033\n",
      "----------------------------------------\n",
      "epoch: 285\n",
      "step 0 loss: 0.028490493074059486\n",
      "step 20 loss: 0.05285092815756798\n",
      "step 40 loss: 0.037656500935554504\n",
      "step 60 loss: 0.06842374801635742\n",
      "\n",
      "accuracy: 0.834\t auroc:0.9011204387137884\n",
      "use time: 11.649352073669434\n",
      "----------------------------------------\n",
      "epoch: 286\n",
      "step 0 loss: 0.05989944934844971\n",
      "step 20 loss: 0.06515659391880035\n",
      "step 40 loss: 0.03920939564704895\n",
      "step 60 loss: 0.03952000290155411\n",
      "\n",
      "accuracy: 0.831\t auroc:0.9009514798383788\n",
      "use time: 11.639908075332642\n",
      "----------------------------------------\n",
      "epoch: 287\n",
      "step 0 loss: 0.041076693683862686\n",
      "step 20 loss: 0.06269928067922592\n",
      "step 40 loss: 0.04895584285259247\n",
      "step 60 loss: 0.06630225479602814\n",
      "\n",
      "accuracy: 0.837\t auroc:0.8957330642864385\n",
      "use time: 11.654703140258789\n",
      "----------------------------------------\n",
      "epoch: 288\n",
      "step 0 loss: 0.027258779853582382\n",
      "step 20 loss: 0.048786312341690063\n",
      "step 40 loss: 0.059135839343070984\n",
      "step 60 loss: 0.06453053653240204\n",
      "\n",
      "accuracy: 0.825\t auroc:0.9004880497801122\n",
      "use time: 11.62995982170105\n",
      "----------------------------------------\n",
      "epoch: 289\n",
      "step 0 loss: 0.02593102678656578\n",
      "step 20 loss: 0.04157373309135437\n",
      "step 40 loss: 0.033895064145326614\n",
      "step 60 loss: 0.05786697193980217\n",
      "\n",
      "accuracy: 0.823\t auroc:0.8950282644061578\n",
      "use time: 11.655523300170898\n",
      "----------------------------------------\n",
      "epoch: 290\n",
      "step 0 loss: 0.04167710989713669\n",
      "step 20 loss: 0.04849790036678314\n",
      "step 40 loss: 0.04238452762365341\n",
      "step 60 loss: 0.051948461681604385\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9004252936263885\n",
      "use time: 11.671485185623169\n",
      "----------------------------------------\n",
      "epoch: 291\n",
      "step 0 loss: 0.045533522963523865\n",
      "step 20 loss: 0.036515358835458755\n",
      "step 40 loss: 0.05793081969022751\n",
      "step 60 loss: 0.05741719529032707\n",
      "\n",
      "accuracy: 0.837\t auroc:0.8950717109741204\n",
      "use time: 11.639366626739502\n",
      "----------------------------------------\n",
      "epoch: 292\n",
      "step 0 loss: 0.047662403434515\n",
      "step 20 loss: 0.031197473406791687\n",
      "step 40 loss: 0.04343051835894585\n",
      "step 60 loss: 0.06199788302183151\n",
      "\n",
      "accuracy: 0.829\t auroc:0.9051706243271818\n",
      "use time: 11.646930694580078\n",
      "----------------------------------------\n",
      "epoch: 293\n",
      "step 0 loss: 0.03263627737760544\n",
      "step 20 loss: 0.04436545819044113\n",
      "step 40 loss: 0.07938771694898605\n",
      "step 60 loss: 0.042283039540052414\n",
      "\n",
      "accuracy: 0.827\t auroc:0.8988322528010968\n",
      "use time: 11.607155799865723\n",
      "----------------------------------------\n",
      "epoch: 294\n",
      "step 0 loss: 0.05715063214302063\n",
      "step 20 loss: 0.034036822617053986\n",
      "step 40 loss: 0.0534328930079937\n",
      "step 60 loss: 0.039267364889383316\n",
      "\n",
      "accuracy: 0.825\t auroc:0.8990132801676072\n",
      "use time: 11.654177904129028\n",
      "----------------------------------------\n",
      "epoch: 295\n",
      "step 0 loss: 0.015460686758160591\n",
      "step 20 loss: 0.06174401938915253\n",
      "step 40 loss: 0.07610923051834106\n",
      "step 60 loss: 0.05794329196214676\n",
      "\n",
      "accuracy: 0.831\t auroc:0.9040651505423579\n",
      "use time: 11.703203439712524\n",
      "----------------------------------------\n",
      "epoch: 296\n",
      "step 0 loss: 0.03872813284397125\n",
      "step 20 loss: 0.04214254766702652\n",
      "step 40 loss: 0.06042057275772095\n",
      "step 60 loss: 0.06482981890439987\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8997253211425482\n",
      "use time: 11.631717681884766\n",
      "----------------------------------------\n",
      "epoch: 297\n",
      "step 0 loss: 0.04002245515584946\n",
      "step 20 loss: 0.05602850392460823\n",
      "step 40 loss: 0.033705443143844604\n",
      "step 60 loss: 0.042950842529535294\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9016948988901816\n",
      "use time: 11.742330074310303\n",
      "----------------------------------------\n",
      "epoch: 298\n",
      "step 0 loss: 0.059552986174821854\n",
      "step 20 loss: 0.06481209397315979\n",
      "step 40 loss: 0.03463069722056389\n",
      "step 60 loss: 0.030504178255796432\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9028969206038108\n",
      "use time: 11.661844491958618\n",
      "----------------------------------------\n",
      "epoch: 299\n",
      "step 0 loss: 0.04971694573760033\n",
      "step 20 loss: 0.05046861246228218\n",
      "step 40 loss: 0.02369137853384018\n",
      "step 60 loss: 0.06390023976564407\n",
      "\n",
      "accuracy: 0.827\t auroc:0.9030465698934593\n",
      "use time: 11.655939817428589\n",
      "----------------------------------------\n",
      "epoch: 300\n",
      "step 0 loss: 0.028265435248613358\n",
      "step 20 loss: 0.0607026107609272\n",
      "step 40 loss: 0.07590289413928986\n",
      "step 60 loss: 0.04200517758727074\n",
      "\n",
      "accuracy: 0.822\t auroc:0.8959454697298106\n",
      "use time: 12.181092977523804\n",
      "----------------------------------------\n",
      "epoch: 301\n",
      "step 0 loss: 0.035279467701911926\n",
      "step 20 loss: 0.0341084860265255\n",
      "step 40 loss: 0.02672034129500389\n",
      "step 60 loss: 0.028511743992567062\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9010963017315872\n",
      "use time: 11.644163131713867\n",
      "----------------------------------------\n",
      "epoch: 302\n",
      "step 0 loss: 0.023029640316963196\n",
      "step 20 loss: 0.05636870488524437\n",
      "step 40 loss: 0.02399875409901142\n",
      "step 60 loss: 0.03561905771493912\n",
      "\n",
      "accuracy: 0.822\t auroc:0.8970026695502314\n",
      "use time: 11.65033221244812\n",
      "----------------------------------------\n",
      "epoch: 303\n",
      "step 0 loss: 0.02887583337724209\n",
      "step 20 loss: 0.05495423823595047\n",
      "step 40 loss: 0.06482201814651489\n",
      "step 60 loss: 0.06201809272170067\n",
      "\n",
      "accuracy: 0.837\t auroc:0.8998604882428759\n",
      "use time: 11.611994981765747\n",
      "----------------------------------------\n",
      "epoch: 304\n",
      "step 0 loss: 0.031118469312787056\n",
      "step 20 loss: 0.030546629801392555\n",
      "step 40 loss: 0.023984558880329132\n",
      "step 60 loss: 0.07981955260038376\n",
      "\n",
      "accuracy: 0.835\t auroc:0.8984267515001134\n",
      "use time: 11.648114442825317\n",
      "----------------------------------------\n",
      "epoch: 305\n",
      "step 0 loss: 0.02702970802783966\n",
      "step 20 loss: 0.0615713894367218\n",
      "step 40 loss: 0.035982053726911545\n",
      "step 60 loss: 0.05095665156841278\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8995756718528995\n",
      "use time: 11.633869409561157\n",
      "----------------------------------------\n",
      "epoch: 306\n",
      "step 0 loss: 0.025769833475351334\n",
      "step 20 loss: 0.04317969083786011\n",
      "step 40 loss: 0.03534630686044693\n",
      "step 60 loss: 0.046510376036167145\n",
      "\n",
      "accuracy: 0.829\t auroc:0.9020376440374414\n",
      "use time: 11.675338983535767\n",
      "----------------------------------------\n",
      "epoch: 307\n",
      "step 0 loss: 0.03558192402124405\n",
      "step 20 loss: 0.03803233057260513\n",
      "step 40 loss: 0.026451120153069496\n",
      "step 60 loss: 0.026585180312395096\n",
      "\n",
      "accuracy: 0.832\t auroc:0.901791446818987\n",
      "use time: 11.628350019454956\n",
      "----------------------------------------\n",
      "epoch: 308\n",
      "step 0 loss: 0.05401467904448509\n",
      "step 20 loss: 0.02536233328282833\n",
      "step 40 loss: 0.04551945626735687\n",
      "step 60 loss: 0.04174110293388367\n",
      "\n",
      "accuracy: 0.828\t auroc:0.9027327891248413\n",
      "use time: 11.716343879699707\n",
      "----------------------------------------\n",
      "epoch: 309\n",
      "step 0 loss: 0.02823619171977043\n",
      "step 20 loss: 0.04928325489163399\n",
      "step 40 loss: 0.042408816516399384\n",
      "step 60 loss: 0.02818026766180992\n",
      "\n",
      "accuracy: 0.834\t auroc:0.9023369426167386\n",
      "use time: 11.604397535324097\n",
      "----------------------------------------\n",
      "epoch: 310\n",
      "step 0 loss: 0.01681804098188877\n",
      "step 20 loss: 0.07222113013267517\n",
      "step 40 loss: 0.03911840543150902\n",
      "step 60 loss: 0.06398054212331772\n",
      "\n",
      "accuracy: 0.82\t auroc:0.9004832223836717\n",
      "use time: 11.60204029083252\n",
      "----------------------------------------\n",
      "epoch: 311\n",
      "step 0 loss: 0.04307665303349495\n",
      "step 20 loss: 0.043427713215351105\n",
      "step 40 loss: 0.04621860384941101\n",
      "step 60 loss: 0.034294456243515015\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9023345289185184\n",
      "use time: 11.648359060287476\n",
      "----------------------------------------\n",
      "epoch: 312\n",
      "step 0 loss: 0.030818969011306763\n",
      "step 20 loss: 0.043808355927467346\n",
      "step 40 loss: 0.019116895273327827\n",
      "step 60 loss: 0.056496512144804\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9065850514841831\n",
      "use time: 11.624556064605713\n",
      "----------------------------------------\n",
      "epoch: 313\n",
      "step 0 loss: 0.026075690984725952\n",
      "step 20 loss: 0.04648724943399429\n",
      "step 40 loss: 0.0682762861251831\n",
      "step 60 loss: 0.0606188103556633\n",
      "\n",
      "accuracy: 0.84\t auroc:0.9042968655714912\n",
      "use time: 11.673020839691162\n",
      "----------------------------------------\n",
      "epoch: 314\n",
      "step 0 loss: 0.030275477096438408\n",
      "step 20 loss: 0.05922360718250275\n",
      "step 40 loss: 0.024401988834142685\n",
      "step 60 loss: 0.014545486308634281\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9029307123788927\n",
      "use time: 11.63683533668518\n",
      "----------------------------------------\n",
      "epoch: 315\n",
      "step 0 loss: 0.024042241275310516\n",
      "step 20 loss: 0.02333807945251465\n",
      "step 40 loss: 0.03331584483385086\n",
      "step 60 loss: 0.03495166450738907\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9039155012527093\n",
      "use time: 11.679105281829834\n",
      "----------------------------------------\n",
      "epoch: 316\n",
      "step 0 loss: 0.025913812220096588\n",
      "step 20 loss: 0.03551926463842392\n",
      "step 40 loss: 0.04532169550657272\n",
      "step 60 loss: 0.03219257667660713\n",
      "\n",
      "accuracy: 0.832\t auroc:0.9050064928482121\n",
      "use time: 11.67961072921753\n",
      "----------------------------------------\n",
      "epoch: 317\n",
      "step 0 loss: 0.04384507238864899\n",
      "step 20 loss: 0.05484906584024429\n",
      "step 40 loss: 0.014530820772051811\n",
      "step 60 loss: 0.029665548354387283\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9048471887656829\n",
      "use time: 11.722941637039185\n",
      "----------------------------------------\n",
      "epoch: 318\n",
      "step 0 loss: 0.011812258511781693\n",
      "step 20 loss: 0.031169939786195755\n",
      "step 40 loss: 0.050210703164339066\n",
      "step 60 loss: 0.021035220474004745\n",
      "\n",
      "accuracy: 0.848\t auroc:0.907087100713972\n",
      "use time: 11.702600240707397\n",
      "----------------------------------------\n",
      "epoch: 319\n",
      "step 0 loss: 0.03442831337451935\n",
      "step 20 loss: 0.06260678917169571\n",
      "step 40 loss: 0.06036140024662018\n",
      "step 60 loss: 0.06020118296146393\n",
      "\n",
      "accuracy: 0.828\t auroc:0.901979715280158\n",
      "use time: 11.717663049697876\n",
      "----------------------------------------\n",
      "epoch: 320\n",
      "step 0 loss: 0.05401688441634178\n",
      "step 20 loss: 0.04663674533367157\n",
      "step 40 loss: 0.03750234097242355\n",
      "step 60 loss: 0.05003214254975319\n",
      "\n",
      "accuracy: 0.836\t auroc:0.8954337657071411\n",
      "use time: 11.64182734489441\n",
      "----------------------------------------\n",
      "epoch: 321\n",
      "step 0 loss: 0.020263712853193283\n",
      "step 20 loss: 0.038452669978141785\n",
      "step 40 loss: 0.0702841579914093\n",
      "step 60 loss: 0.052664127200841904\n",
      "\n",
      "accuracy: 0.827\t auroc:0.8953492862694362\n",
      "use time: 11.62665319442749\n",
      "----------------------------------------\n",
      "epoch: 322\n",
      "step 0 loss: 0.028970016166567802\n",
      "step 20 loss: 0.10059916228055954\n",
      "step 40 loss: 0.026985343545675278\n",
      "step 60 loss: 0.031621042639017105\n",
      "\n",
      "accuracy: 0.838\t auroc:0.906290580301326\n",
      "use time: 11.672637701034546\n",
      "----------------------------------------\n",
      "epoch: 323\n",
      "step 0 loss: 0.04216078668832779\n",
      "step 20 loss: 0.0589546263217926\n",
      "step 40 loss: 0.023236995562911034\n",
      "step 60 loss: 0.07771556824445724\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9013811181215634\n",
      "use time: 11.635178804397583\n",
      "----------------------------------------\n",
      "epoch: 324\n",
      "step 0 loss: 0.05689975246787071\n",
      "step 20 loss: 0.04048071801662445\n",
      "step 40 loss: 0.03098928928375244\n",
      "step 60 loss: 0.07379308342933655\n",
      "\n",
      "accuracy: 0.839\t auroc:0.9046251285294302\n",
      "use time: 11.64404010772705\n",
      "----------------------------------------\n",
      "epoch: 325\n",
      "step 0 loss: 0.01577037200331688\n",
      "step 20 loss: 0.04352136701345444\n",
      "step 40 loss: 0.018440742045640945\n",
      "step 60 loss: 0.03407905250787735\n",
      "\n",
      "accuracy: 0.835\t auroc:0.9015355948076523\n",
      "use time: 11.645971775054932\n",
      "----------------------------------------\n",
      "epoch: 326\n",
      "step 0 loss: 0.05298212170600891\n",
      "step 20 loss: 0.0419173389673233\n",
      "step 40 loss: 0.05721192806959152\n",
      "step 60 loss: 0.029314734041690826\n",
      "\n",
      "accuracy: 0.819\t auroc:0.9026652055746773\n",
      "use time: 11.668629884719849\n",
      "----------------------------------------\n",
      "epoch: 327\n",
      "step 0 loss: 0.024050170555710793\n",
      "step 20 loss: 0.04459120333194733\n",
      "step 40 loss: 0.04230741411447525\n",
      "step 60 loss: 0.04452713578939438\n",
      "\n",
      "accuracy: 0.831\t auroc:0.9041665258676038\n",
      "use time: 11.646488189697266\n",
      "----------------------------------------\n",
      "epoch: 328\n",
      "step 0 loss: 0.029511237516999245\n",
      "step 20 loss: 0.050108812749385834\n",
      "step 40 loss: 0.0411633737385273\n",
      "step 60 loss: 0.04654747247695923\n",
      "\n",
      "accuracy: 0.842\t auroc:0.9049292545051678\n",
      "use time: 11.64384412765503\n",
      "----------------------------------------\n",
      "epoch: 329\n",
      "step 0 loss: 0.02826712466776371\n",
      "step 20 loss: 0.030829142779111862\n",
      "step 40 loss: 0.02732398547232151\n",
      "step 60 loss: 0.030981360003352165\n",
      "\n",
      "accuracy: 0.837\t auroc:0.900434948419269\n",
      "use time: 11.665028095245361\n",
      "----------------------------------------\n",
      "epoch: 330\n",
      "step 0 loss: 0.057795312255620956\n",
      "step 20 loss: 0.046366602182388306\n",
      "step 40 loss: 0.022449079900979996\n",
      "step 60 loss: 0.04057835787534714\n",
      "\n",
      "accuracy: 0.829\t auroc:0.9052140708951442\n",
      "use time: 11.667567014694214\n",
      "----------------------------------------\n",
      "epoch: 331\n",
      "step 0 loss: 0.026805609464645386\n",
      "step 20 loss: 0.0410413034260273\n",
      "step 40 loss: 0.0387362539768219\n",
      "step 60 loss: 0.04916064813733101\n",
      "\n",
      "accuracy: 0.832\t auroc:0.8994984335098551\n",
      "use time: 11.652665138244629\n",
      "----------------------------------------\n",
      "epoch: 332\n",
      "step 0 loss: 0.03165242075920105\n",
      "step 20 loss: 0.060314908623695374\n",
      "step 40 loss: 0.015173228457570076\n",
      "step 60 loss: 0.05296583101153374\n",
      "\n",
      "accuracy: 0.824\t auroc:0.8969495681893883\n",
      "use time: 11.610438823699951\n",
      "----------------------------------------\n",
      "epoch: 333\n",
      "step 0 loss: 0.04146266356110573\n",
      "step 20 loss: 0.035414718091487885\n",
      "step 40 loss: 0.015604376792907715\n",
      "step 60 loss: 0.07860986888408661\n",
      "\n",
      "accuracy: 0.826\t auroc:0.893884171449812\n",
      "use time: 12.137988090515137\n",
      "----------------------------------------\n",
      "epoch: 334\n",
      "step 0 loss: 0.033645693212747574\n",
      "step 20 loss: 0.04349623620510101\n",
      "step 40 loss: 0.019920796155929565\n",
      "step 60 loss: 0.03758826106786728\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8976591954661093\n",
      "use time: 11.61076831817627\n",
      "----------------------------------------\n",
      "epoch: 335\n",
      "step 0 loss: 0.022831324487924576\n",
      "step 20 loss: 0.039670951664447784\n",
      "step 40 loss: 0.02574634738266468\n",
      "step 60 loss: 0.04921852797269821\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8994839513205343\n",
      "use time: 11.600879669189453\n",
      "----------------------------------------\n",
      "epoch: 336\n",
      "step 0 loss: 0.016131829470396042\n",
      "step 20 loss: 0.045012008398771286\n",
      "step 40 loss: 0.03889216482639313\n",
      "step 60 loss: 0.04285312443971634\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8943741521885002\n",
      "use time: 11.620834827423096\n",
      "----------------------------------------\n",
      "epoch: 337\n",
      "step 0 loss: 0.012112610042095184\n",
      "step 20 loss: 0.05616004392504692\n",
      "step 40 loss: 0.022600367665290833\n",
      "step 60 loss: 0.025155125185847282\n",
      "\n",
      "accuracy: 0.838\t auroc:0.902274186463015\n",
      "use time: 11.61164402961731\n",
      "----------------------------------------\n",
      "epoch: 338\n",
      "step 0 loss: 0.04582314193248749\n",
      "step 20 loss: 0.04512178152799606\n",
      "step 40 loss: 0.061064086854457855\n",
      "step 60 loss: 0.04468420892953873\n",
      "\n",
      "accuracy: 0.843\t auroc:0.9023996987704622\n",
      "use time: 11.56236982345581\n",
      "----------------------------------------\n",
      "epoch: 339\n",
      "step 0 loss: 0.012061726301908493\n",
      "step 20 loss: 0.022573063150048256\n",
      "step 40 loss: 0.03109341487288475\n",
      "step 60 loss: 0.030924580991268158\n",
      "\n",
      "accuracy: 0.832\t auroc:0.9056243995925677\n",
      "use time: 11.649914026260376\n",
      "----------------------------------------\n",
      "epoch: 340\n",
      "step 0 loss: 0.027058374136686325\n",
      "step 20 loss: 0.02098982408642769\n",
      "step 40 loss: 0.03351706266403198\n",
      "step 60 loss: 0.025087974965572357\n",
      "\n",
      "accuracy: 0.834\t auroc:0.8993343020308857\n",
      "use time: 11.672537803649902\n",
      "----------------------------------------\n",
      "epoch: 341\n",
      "step 0 loss: 0.02453550323843956\n",
      "step 20 loss: 0.026450999081134796\n",
      "step 40 loss: 0.05151402950286865\n",
      "step 60 loss: 0.020184822380542755\n",
      "\n",
      "accuracy: 0.835\t auroc:0.9015500769969732\n",
      "use time: 11.688076734542847\n",
      "----------------------------------------\n",
      "epoch: 342\n",
      "step 0 loss: 0.044589921832084656\n",
      "step 20 loss: 0.039406877011060715\n",
      "step 40 loss: 0.02570146694779396\n",
      "step 60 loss: 0.04639403522014618\n",
      "\n",
      "accuracy: 0.831\t auroc:0.9048351202745823\n",
      "use time: 11.620939254760742\n",
      "----------------------------------------\n",
      "epoch: 343\n",
      "step 0 loss: 0.029272597283124924\n",
      "step 20 loss: 0.03483404591679573\n",
      "step 40 loss: 0.0269424207508564\n",
      "step 60 loss: 0.05092616751790047\n",
      "\n",
      "accuracy: 0.832\t auroc:0.8976495406732287\n",
      "use time: 11.648747205734253\n",
      "----------------------------------------\n",
      "epoch: 344\n",
      "step 0 loss: 0.018923958763480186\n",
      "step 20 loss: 0.03952469676733017\n",
      "step 40 loss: 0.017333386465907097\n",
      "step 60 loss: 0.05390501022338867\n",
      "\n",
      "accuracy: 0.833\t auroc:0.8968626750534635\n",
      "use time: 11.701820373535156\n",
      "----------------------------------------\n",
      "epoch: 345\n",
      "step 0 loss: 0.025883568450808525\n",
      "step 20 loss: 0.03401818126440048\n",
      "step 40 loss: 0.03948676958680153\n",
      "step 60 loss: 0.01969553343951702\n",
      "\n",
      "accuracy: 0.835\t auroc:0.9049920106588913\n",
      "use time: 11.694172620773315\n",
      "----------------------------------------\n",
      "epoch: 346\n",
      "step 0 loss: 0.026650357991456985\n",
      "step 20 loss: 0.03252056613564491\n",
      "step 40 loss: 0.03324052691459656\n",
      "step 60 loss: 0.03914792090654373\n",
      "\n",
      "accuracy: 0.834\t auroc:0.9021583289484483\n",
      "use time: 11.67308497428894\n",
      "----------------------------------------\n",
      "epoch: 347\n",
      "step 0 loss: 0.03899591416120529\n",
      "step 20 loss: 0.03336891531944275\n",
      "step 40 loss: 0.06625321507453918\n",
      "step 60 loss: 0.0254130307585001\n",
      "\n",
      "accuracy: 0.839\t auroc:0.8987694966473732\n",
      "use time: 11.716186046600342\n",
      "----------------------------------------\n",
      "epoch: 348\n",
      "step 0 loss: 0.05778678506612778\n",
      "step 20 loss: 0.03869299590587616\n",
      "step 40 loss: 0.04375201091170311\n",
      "step 60 loss: 0.036647092550992966\n",
      "\n",
      "accuracy: 0.827\t auroc:0.8975819571230648\n",
      "use time: 11.698739528656006\n",
      "----------------------------------------\n",
      "epoch: 349\n",
      "step 0 loss: 0.03824494034051895\n",
      "step 20 loss: 0.028365839272737503\n",
      "step 40 loss: 0.036787670105695724\n",
      "step 60 loss: 0.04511082172393799\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9033362136798759\n",
      "use time: 11.734165906906128\n",
      "----------------------------------------\n",
      "epoch: 350\n",
      "step 0 loss: 0.02832784131169319\n",
      "step 20 loss: 0.035189010202884674\n",
      "step 40 loss: 0.025893239304423332\n",
      "step 60 loss: 0.029662856832146645\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9021438467591275\n",
      "use time: 11.78520655632019\n",
      "----------------------------------------\n",
      "epoch: 351\n",
      "step 0 loss: 0.0212375707924366\n",
      "step 20 loss: 0.016804935410618782\n",
      "step 40 loss: 0.017128583043813705\n",
      "step 60 loss: 0.03036484494805336\n",
      "\n",
      "accuracy: 0.832\t auroc:0.9041085971103204\n",
      "use time: 11.691763877868652\n",
      "----------------------------------------\n",
      "epoch: 352\n",
      "step 0 loss: 0.02279200404882431\n",
      "step 20 loss: 0.026218555867671967\n",
      "step 40 loss: 0.0185135118663311\n",
      "step 60 loss: 0.028140591457486153\n",
      "\n",
      "accuracy: 0.826\t auroc:0.8961168423034405\n",
      "use time: 11.692914247512817\n",
      "----------------------------------------\n",
      "epoch: 353\n",
      "step 0 loss: 0.021891582757234573\n",
      "step 20 loss: 0.07611516863107681\n",
      "step 40 loss: 0.038598284125328064\n",
      "step 60 loss: 0.04122535511851311\n",
      "\n",
      "accuracy: 0.835\t auroc:0.8994236088650308\n",
      "use time: 11.591887474060059\n",
      "----------------------------------------\n",
      "epoch: 354\n",
      "step 0 loss: 0.035307835787534714\n",
      "step 20 loss: 0.025061681866645813\n",
      "step 40 loss: 0.028441153466701508\n",
      "step 60 loss: 0.0369720458984375\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9057064653320525\n",
      "use time: 11.647276163101196\n",
      "----------------------------------------\n",
      "epoch: 355\n",
      "step 0 loss: 0.014502649195492268\n",
      "step 20 loss: 0.035047855228185654\n",
      "step 40 loss: 0.04186045378446579\n",
      "step 60 loss: 0.020480845123529434\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9010890606369267\n",
      "use time: 11.655737161636353\n",
      "----------------------------------------\n",
      "epoch: 356\n",
      "step 0 loss: 0.029880693182349205\n",
      "step 20 loss: 0.02896709181368351\n",
      "step 40 loss: 0.02774403616786003\n",
      "step 60 loss: 0.018428172916173935\n",
      "\n",
      "accuracy: 0.839\t auroc:0.9029958822308364\n",
      "use time: 11.721163034439087\n",
      "----------------------------------------\n",
      "epoch: 357\n",
      "step 0 loss: 0.030196011066436768\n",
      "step 20 loss: 0.02464761771261692\n",
      "step 40 loss: 0.022860750555992126\n",
      "step 60 loss: 0.018208736553788185\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9078401745586553\n",
      "use time: 11.683967113494873\n",
      "----------------------------------------\n",
      "epoch: 358\n",
      "step 0 loss: 0.023615647107362747\n",
      "step 20 loss: 0.05004160851240158\n",
      "step 40 loss: 0.03061756305396557\n",
      "step 60 loss: 0.045155368745326996\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9053588927883525\n",
      "use time: 11.653260231018066\n",
      "----------------------------------------\n",
      "epoch: 359\n",
      "step 0 loss: 0.008295082487165928\n",
      "step 20 loss: 0.04675973206758499\n",
      "step 40 loss: 0.04404816776514053\n",
      "step 60 loss: 0.04891703650355339\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9069953801816066\n",
      "use time: 11.606887578964233\n",
      "----------------------------------------\n",
      "epoch: 360\n",
      "step 0 loss: 0.04610664024949074\n",
      "step 20 loss: 0.02764277532696724\n",
      "step 40 loss: 0.030919456854462624\n",
      "step 60 loss: 0.027865435928106308\n",
      "\n",
      "accuracy: 0.846\t auroc:0.9023755617882606\n",
      "use time: 11.637158632278442\n",
      "----------------------------------------\n",
      "epoch: 361\n",
      "step 0 loss: 0.053937189280986786\n",
      "step 20 loss: 0.048317212611436844\n",
      "step 40 loss: 0.006235949695110321\n",
      "step 60 loss: 0.03852436691522598\n",
      "\n",
      "accuracy: 0.835\t auroc:0.899199134930558\n",
      "use time: 11.674738645553589\n",
      "----------------------------------------\n",
      "epoch: 362\n",
      "step 0 loss: 0.016883840784430504\n",
      "step 20 loss: 0.052086010575294495\n",
      "step 40 loss: 0.03186739236116409\n",
      "step 60 loss: 0.03507481515407562\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9055326790602024\n",
      "use time: 11.66325330734253\n",
      "----------------------------------------\n",
      "epoch: 363\n",
      "step 0 loss: 0.024966523051261902\n",
      "step 20 loss: 0.041028156876564026\n",
      "step 40 loss: 0.0708284080028534\n",
      "step 60 loss: 0.02782854251563549\n",
      "\n",
      "accuracy: 0.844\t auroc:0.9106690288726581\n",
      "use time: 11.672420978546143\n",
      "----------------------------------------\n",
      "epoch: 364\n",
      "step 0 loss: 0.013125578872859478\n",
      "step 20 loss: 0.025380244478583336\n",
      "step 40 loss: 0.018161538988351822\n",
      "step 60 loss: 0.027424423024058342\n",
      "\n",
      "accuracy: 0.835\t auroc:0.9024262494508836\n",
      "use time: 11.727657318115234\n",
      "----------------------------------------\n",
      "epoch: 365\n",
      "step 0 loss: 0.02344452776014805\n",
      "step 20 loss: 0.040100984275341034\n",
      "step 40 loss: 0.021492084488272667\n",
      "step 60 loss: 0.022185107693076134\n",
      "\n",
      "accuracy: 0.832\t auroc:0.900227370372337\n",
      "use time: 11.680423736572266\n",
      "----------------------------------------\n",
      "epoch: 366\n",
      "step 0 loss: 0.012488894164562225\n",
      "step 20 loss: 0.04150015860795975\n",
      "step 40 loss: 0.026163700968027115\n",
      "step 60 loss: 0.052270714193582535\n",
      "\n",
      "accuracy: 0.838\t auroc:0.8999618635681218\n",
      "use time: 11.654363632202148\n",
      "----------------------------------------\n",
      "epoch: 367\n",
      "step 0 loss: 0.011242560110986233\n",
      "step 20 loss: 0.042892903089523315\n",
      "step 40 loss: 0.02957938052713871\n",
      "step 60 loss: 0.04022543877363205\n",
      "\n",
      "accuracy: 0.824\t auroc:0.8970195654377726\n",
      "use time: 11.631927490234375\n",
      "----------------------------------------\n",
      "epoch: 368\n",
      "step 0 loss: 0.02194967120885849\n",
      "step 20 loss: 0.04747438430786133\n",
      "step 40 loss: 0.06100371107459068\n",
      "step 60 loss: 0.04011654481291771\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8947120699393196\n",
      "use time: 11.672570705413818\n",
      "----------------------------------------\n",
      "epoch: 369\n",
      "step 0 loss: 0.05019557476043701\n",
      "step 20 loss: 0.028532028198242188\n",
      "step 40 loss: 0.021085824817419052\n",
      "step 60 loss: 0.027827244251966476\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9015983509613761\n",
      "use time: 12.264591932296753\n",
      "----------------------------------------\n",
      "epoch: 370\n",
      "step 0 loss: 0.04201192408800125\n",
      "step 20 loss: 0.028750356286764145\n",
      "step 40 loss: 0.030982263386249542\n",
      "step 60 loss: 0.032017648220062256\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9042847970803907\n",
      "use time: 11.705740690231323\n",
      "----------------------------------------\n",
      "epoch: 371\n",
      "step 0 loss: 0.016875579953193665\n",
      "step 20 loss: 0.020408712327480316\n",
      "step 40 loss: 0.00831493828445673\n",
      "step 60 loss: 0.021365193650126457\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9026338274978156\n",
      "use time: 11.711616516113281\n",
      "----------------------------------------\n",
      "epoch: 372\n",
      "step 0 loss: 0.027191024273633957\n",
      "step 20 loss: 0.04835686832666397\n",
      "step 40 loss: 0.038903869688510895\n",
      "step 60 loss: 0.022884974256157875\n",
      "\n",
      "accuracy: 0.835\t auroc:0.8994260225632509\n",
      "use time: 11.704704284667969\n",
      "----------------------------------------\n",
      "epoch: 373\n",
      "step 0 loss: 0.02804546430706978\n",
      "step 20 loss: 0.022137276828289032\n",
      "step 40 loss: 0.017819266766309738\n",
      "step 60 loss: 0.008160753175616264\n",
      "\n",
      "accuracy: 0.832\t auroc:0.900659422353742\n",
      "use time: 11.724525928497314\n",
      "----------------------------------------\n",
      "epoch: 374\n",
      "step 0 loss: 0.019841177389025688\n",
      "step 20 loss: 0.03503886237740517\n",
      "step 40 loss: 0.028425028547644615\n",
      "step 60 loss: 0.025823216885328293\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9035317232357073\n",
      "use time: 11.724313259124756\n",
      "----------------------------------------\n",
      "epoch: 375\n",
      "step 0 loss: 0.028015924617648125\n",
      "step 20 loss: 0.014469804242253304\n",
      "step 40 loss: 0.03660963475704193\n",
      "step 60 loss: 0.03940630704164505\n",
      "\n",
      "accuracy: 0.842\t auroc:0.9054602681135983\n",
      "use time: 11.697614192962646\n",
      "----------------------------------------\n",
      "epoch: 376\n",
      "step 0 loss: 0.02140987105667591\n",
      "step 20 loss: 0.032380685210227966\n",
      "step 40 loss: 0.008274044841527939\n",
      "step 60 loss: 0.023990174755454063\n",
      "\n",
      "accuracy: 0.838\t auroc:0.9041761806604844\n",
      "use time: 11.691239356994629\n",
      "----------------------------------------\n",
      "epoch: 377\n",
      "step 0 loss: 0.013395201414823532\n",
      "step 20 loss: 0.04268192499876022\n",
      "step 40 loss: 0.024648353457450867\n",
      "step 60 loss: 0.03479596972465515\n",
      "\n",
      "accuracy: 0.822\t auroc:0.8903674131430696\n",
      "use time: 11.683757305145264\n",
      "----------------------------------------\n",
      "epoch: 378\n",
      "step 0 loss: 0.0208220686763525\n",
      "step 20 loss: 0.029454227536916733\n",
      "step 40 loss: 0.028039727360010147\n",
      "step 60 loss: 0.0070698680356144905\n",
      "\n",
      "accuracy: 0.837\t auroc:0.895117571240303\n",
      "use time: 11.711018800735474\n",
      "----------------------------------------\n",
      "epoch: 379\n",
      "step 0 loss: 0.03682874143123627\n",
      "step 20 loss: 0.03616729751229286\n",
      "step 40 loss: 0.01934608817100525\n",
      "step 60 loss: 0.024175966158509254\n",
      "\n",
      "accuracy: 0.839\t auroc:0.9002273703723371\n",
      "use time: 11.694111585617065\n",
      "----------------------------------------\n",
      "epoch: 380\n",
      "step 0 loss: 0.01805281639099121\n",
      "step 20 loss: 0.03829730302095413\n",
      "step 40 loss: 0.05401597544550896\n",
      "step 60 loss: 0.018971610814332962\n",
      "\n",
      "accuracy: 0.832\t auroc:0.9015935235649357\n",
      "use time: 11.687780380249023\n",
      "----------------------------------------\n",
      "epoch: 381\n",
      "step 0 loss: 0.022183910012245178\n",
      "step 20 loss: 0.03789879009127617\n",
      "step 40 loss: 0.007748611271381378\n",
      "step 60 loss: 0.029010744765400887\n",
      "\n",
      "accuracy: 0.843\t auroc:0.8993680938059676\n",
      "use time: 11.75627589225769\n",
      "----------------------------------------\n",
      "epoch: 382\n",
      "step 0 loss: 0.024558883160352707\n",
      "step 20 loss: 0.02165801078081131\n",
      "step 40 loss: 0.03231946751475334\n",
      "step 60 loss: 0.03724908083677292\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9033144903958947\n",
      "use time: 11.74031376838684\n",
      "----------------------------------------\n",
      "epoch: 383\n",
      "step 0 loss: 0.03521057590842247\n",
      "step 20 loss: 0.029564855620265007\n",
      "step 40 loss: 0.020462628453969955\n",
      "step 60 loss: 0.012128068134188652\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9021124686822655\n",
      "use time: 11.759824752807617\n",
      "----------------------------------------\n",
      "epoch: 384\n",
      "step 0 loss: 0.011489036493003368\n",
      "step 20 loss: 0.028158213943243027\n",
      "step 40 loss: 0.026612194254994392\n",
      "step 60 loss: 0.015089419670403004\n",
      "\n",
      "accuracy: 0.84\t auroc:0.9032589753368316\n",
      "use time: 11.74235463142395\n",
      "----------------------------------------\n",
      "epoch: 385\n",
      "step 0 loss: 0.01774214580655098\n",
      "step 20 loss: 0.019549254328012466\n",
      "step 40 loss: 0.024037620052695274\n",
      "step 60 loss: 0.022435063496232033\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9014487016717274\n",
      "use time: 11.73259449005127\n",
      "----------------------------------------\n",
      "epoch: 386\n",
      "step 0 loss: 0.037757743149995804\n",
      "step 20 loss: 0.03468095511198044\n",
      "step 40 loss: 0.015018834732472897\n",
      "step 60 loss: 0.02512574940919876\n",
      "\n",
      "accuracy: 0.834\t auroc:0.8974516174191771\n",
      "use time: 11.705553531646729\n",
      "----------------------------------------\n",
      "epoch: 387\n",
      "step 0 loss: 0.013591134920716286\n",
      "step 20 loss: 0.029705626890063286\n",
      "step 40 loss: 0.048810750246047974\n",
      "step 60 loss: 0.024426382035017014\n",
      "\n",
      "accuracy: 0.83\t auroc:0.9021752248359892\n",
      "use time: 11.675407886505127\n",
      "----------------------------------------\n",
      "epoch: 388\n",
      "step 0 loss: 0.010570472106337547\n",
      "step 20 loss: 0.016937632113695145\n",
      "step 40 loss: 0.04200076311826706\n",
      "step 60 loss: 0.022075694054365158\n",
      "\n",
      "accuracy: 0.833\t auroc:0.9007294196021259\n",
      "use time: 11.700878381729126\n",
      "----------------------------------------\n",
      "epoch: 389\n",
      "step 0 loss: 0.02730661630630493\n",
      "step 20 loss: 0.05260039493441582\n",
      "step 40 loss: 0.031207261607050896\n",
      "step 60 loss: 0.02828502096235752\n",
      "\n",
      "accuracy: 0.829\t auroc:0.9019507509015162\n",
      "use time: 11.691247463226318\n",
      "----------------------------------------\n",
      "epoch: 390\n",
      "step 0 loss: 0.013110227882862091\n",
      "step 20 loss: 0.03628745675086975\n",
      "step 40 loss: 0.011509839445352554\n",
      "step 60 loss: 0.06341290473937988\n",
      "\n",
      "accuracy: 0.832\t auroc:0.9005845977089177\n",
      "use time: 11.70926022529602\n",
      "----------------------------------------\n",
      "epoch: 391\n",
      "step 0 loss: 0.030771497637033463\n",
      "step 20 loss: 0.03234844282269478\n",
      "step 40 loss: 0.018762219697237015\n",
      "step 60 loss: 0.05644910782575607\n",
      "\n",
      "accuracy: 0.84\t auroc:0.9027231343319606\n",
      "use time: 11.678137063980103\n",
      "----------------------------------------\n",
      "epoch: 392\n",
      "step 0 loss: 0.026322074234485626\n",
      "step 20 loss: 0.029734421521425247\n",
      "step 40 loss: 0.015129856765270233\n",
      "step 60 loss: 0.02306988835334778\n",
      "\n",
      "accuracy: 0.841\t auroc:0.9020835043036238\n",
      "use time: 11.651661157608032\n",
      "----------------------------------------\n",
      "epoch: 393\n",
      "step 0 loss: 0.013588563539087772\n",
      "step 20 loss: 0.049088235944509506\n",
      "step 40 loss: 0.047669753432273865\n",
      "step 60 loss: 0.013983095064759254\n",
      "\n",
      "accuracy: 0.838\t auroc:0.902259704273694\n",
      "use time: 11.699276447296143\n",
      "----------------------------------------\n",
      "epoch: 394\n",
      "step 0 loss: 0.023741774260997772\n",
      "step 20 loss: 0.024183113127946854\n",
      "step 40 loss: 0.021262235939502716\n",
      "step 60 loss: 0.024726321920752525\n",
      "\n",
      "accuracy: 0.842\t auroc:0.9076325965117233\n",
      "use time: 11.709553718566895\n",
      "----------------------------------------\n",
      "epoch: 395\n",
      "step 0 loss: 0.0470113605260849\n",
      "step 20 loss: 0.015460433438420296\n",
      "step 40 loss: 0.0188167504966259\n",
      "step 60 loss: 0.026013150811195374\n",
      "\n",
      "accuracy: 0.835\t auroc:0.8986319158488252\n",
      "use time: 11.656835079193115\n",
      "----------------------------------------\n",
      "epoch: 396\n",
      "step 0 loss: 0.0167897529900074\n",
      "step 20 loss: 0.03208892419934273\n",
      "step 40 loss: 0.030072428286075592\n",
      "step 60 loss: 0.023757722228765488\n",
      "\n",
      "accuracy: 0.83\t auroc:0.9007149374128052\n",
      "use time: 11.688266277313232\n",
      "----------------------------------------\n",
      "epoch: 397\n",
      "step 0 loss: 0.023844614624977112\n",
      "step 20 loss: 0.015917383134365082\n",
      "step 40 loss: 0.038373351097106934\n",
      "step 60 loss: 0.043902259320020676\n",
      "\n",
      "accuracy: 0.829\t auroc:0.8992256856109794\n",
      "use time: 11.604838371276855\n",
      "----------------------------------------\n",
      "epoch: 398\n",
      "step 0 loss: 0.016469964757561684\n",
      "step 20 loss: 0.0195587407797575\n",
      "step 40 loss: 0.028170431032776833\n",
      "step 60 loss: 0.017864182591438293\n",
      "\n",
      "accuracy: 0.84\t auroc:0.8995515348706982\n",
      "use time: 11.783287286758423\n",
      "----------------------------------------\n",
      "epoch: 399\n",
      "step 0 loss: 0.013466419652104378\n",
      "step 20 loss: 0.05194710195064545\n",
      "step 40 loss: 0.019825903698801994\n",
      "step 60 loss: 0.022454077377915382\n",
      "\n",
      "accuracy: 0.842\t auroc:0.9000777210826885\n",
      "use time: 11.608548879623413\n",
      "----------------------------------------\n",
      "epoch: 400\n",
      "step 0 loss: 0.01769407093524933\n",
      "step 20 loss: 0.024810604751110077\n",
      "step 40 loss: 0.019957944750785828\n",
      "step 60 loss: 0.0320560447871685\n",
      "\n",
      "accuracy: 0.832\t auroc:0.9017576550439053\n",
      "use time: 11.663472890853882\n",
      "----------------------------------------\n",
      "epoch: 401\n",
      "step 0 loss: 0.0186060331761837\n",
      "step 20 loss: 0.049619875848293304\n",
      "step 40 loss: 0.020883983001112938\n",
      "step 60 loss: 0.019452380016446114\n",
      "\n",
      "accuracy: 0.842\t auroc:0.8975964393123856\n",
      "use time: 11.6396324634552\n",
      "----------------------------------------\n",
      "epoch: 402\n",
      "step 0 loss: 0.04329682141542435\n",
      "step 20 loss: 0.026652343571186066\n",
      "step 40 loss: 0.06511496752500534\n",
      "step 60 loss: 0.04017111659049988\n",
      "\n",
      "accuracy: 0.832\t auroc:0.8974226530405357\n",
      "use time: 11.639534711837769\n",
      "----------------------------------------\n",
      "epoch: 403\n",
      "step 0 loss: 0.024651803076267242\n",
      "step 20 loss: 0.04719499126076698\n",
      "step 40 loss: 0.010208537802100182\n",
      "step 60 loss: 0.006094284355640411\n",
      "\n",
      "accuracy: 0.837\t auroc:0.9032782849225927\n",
      "use time: 11.650294303894043\n",
      "----------------------------------------\n",
      "epoch: 404\n",
      "step 0 loss: 0.014193576760590076\n",
      "step 20 loss: 0.04771868512034416\n",
      "step 40 loss: 0.017083756625652313\n",
      "step 60 loss: 0.012155146338045597\n",
      "\n",
      "accuracy: 0.831\t auroc:0.90044943060859\n",
      "use time: 11.663360595703125\n",
      "----------------------------------------\n",
      "epoch: 405\n",
      "step 0 loss: 0.010802030563354492\n",
      "step 20 loss: 0.032938070595264435\n",
      "step 40 loss: 0.030094530433416367\n",
      "step 60 loss: 0.021616768091917038\n",
      "\n",
      "accuracy: 0.828\t auroc:0.8981346940154766\n",
      "use time: 11.658179521560669\n",
      "----------------------------------------\n",
      "epoch: 406\n",
      "step 0 loss: 0.018473703414201736\n",
      "step 20 loss: 0.011627739295363426\n",
      "step 40 loss: 0.018779125064611435\n",
      "step 60 loss: 0.022604847326874733\n",
      "\n",
      "accuracy: 0.838\t auroc:0.901303879778519\n",
      "use time: 11.711825847625732\n",
      "----------------------------------------\n",
      "epoch: 407\n",
      "step 0 loss: 0.014129018411040306\n",
      "step 20 loss: 0.007478607352823019\n",
      "step 40 loss: 0.02599353715777397\n",
      "step 60 loss: 0.026652123779058456\n",
      "\n",
      "accuracy: 0.83\t auroc:0.8989239733334621\n",
      "use time: 11.743698596954346\n",
      "----------------------------------------\n",
      "epoch: 408\n",
      "step 0 loss: 0.019899172708392143\n",
      "step 20 loss: 0.059007514268159866\n",
      "step 40 loss: 0.024016331881284714\n",
      "step 60 loss: 0.036450501531362534\n",
      "\n",
      "accuracy: 0.842\t auroc:0.904726503854676\n",
      "use time: 11.680302619934082\n",
      "----------------------------------------\n",
      "epoch: 409\n",
      "step 0 loss: 0.04011057689785957\n",
      "step 20 loss: 0.027097921818494797\n",
      "step 40 loss: 0.02312707155942917\n",
      "step 60 loss: 0.03536517545580864\n",
      "\n",
      "accuracy: 0.836\t auroc:0.9043861724056365\n",
      "use time: 12.36228346824646\n",
      "----------------------------------------\n",
      "epoch: 410\n",
      "step 0 loss: 0.0348895862698555\n",
      "step 20 loss: 0.015843123197555542\n",
      "step 40 loss: 0.006039470434188843\n",
      "step 60 loss: 0.02661788836121559\n",
      "\n",
      "accuracy: 0.828\t auroc:0.9009804442170204\n",
      "use time: 11.64496111869812\n",
      "----------------------------------------\n",
      "epoch: 411\n",
      "step 0 loss: 0.018980732187628746\n",
      "step 20 loss: 0.026981763541698456\n",
      "step 40 loss: 0.0412694588303566\n",
      "step 60 loss: 0.021798234432935715\n",
      "\n",
      "accuracy: 0.834\t auroc:0.8977847077735565\n",
      "use time: 11.652066230773926\n",
      "----------------------------------------\n",
      "epoch: 412\n",
      "step 0 loss: 0.01895192079246044\n",
      "step 20 loss: 0.023933829739689827\n",
      "step 40 loss: 0.012863483279943466\n",
      "step 60 loss: 0.03357306867837906\n",
      "\n",
      "accuracy: 0.832\t auroc:0.8997977320891525\n",
      "use time: 11.718894481658936\n",
      "----------------------------------------\n",
      "epoch: 413\n",
      "step 0 loss: 0.019626153632998466\n",
      "step 20 loss: 0.02513715624809265\n",
      "step 40 loss: 0.009948687627911568\n",
      "step 60 loss: 0.03999124839901924\n",
      "\n",
      "accuracy: 0.831\t auroc:0.8967709545210982\n",
      "use time: 11.6738440990448\n",
      "----------------------------------------\n",
      "epoch: 414\n",
      "step 0 loss: 0.01726458966732025\n",
      "step 20 loss: 0.040063925087451935\n",
      "step 40 loss: 0.02953343093395233\n",
      "step 60 loss: 0.01362965814769268\n",
      "\n",
      "accuracy: 0.84\t auroc:0.8978040173593176\n",
      "use time: 11.678146600723267\n",
      "----------------------------------------\n",
      "epoch: 415\n",
      "step 0 loss: 0.020825741812586784\n",
      "step 20 loss: 0.031368136405944824\n",
      "step 40 loss: 0.0317959301173687\n",
      "step 60 loss: 0.03592746704816818\n",
      "\n",
      "accuracy: 0.836\t auroc:0.8951610178082654\n",
      "use time: 11.696581840515137\n",
      "----------------------------------------\n",
      "epoch: 416\n",
      "step 0 loss: 0.02449069172143936\n",
      "step 20 loss: 0.016259152442216873\n",
      "step 40 loss: 0.007473581004887819\n",
      "step 60 loss: 0.07693946361541748\n",
      "\n",
      "accuracy: 0.848\t auroc:0.9044151367842781\n",
      "use time: 11.680911302566528\n",
      "----------------------------------------\n",
      "epoch: 417\n",
      "step 0 loss: 0.02719714492559433\n",
      "step 20 loss: 0.02447541058063507\n",
      "step 40 loss: 0.012269945815205574\n",
      "step 60 loss: 0.04743010550737381\n",
      "\n",
      "accuracy: 0.835\t auroc:0.9002973676207211\n",
      "use time: 11.66349744796753\n",
      "----------------------------------------\n",
      "epoch: 418\n",
      "step 0 loss: 0.014498433098196983\n",
      "step 20 loss: 0.02128758281469345\n",
      "step 40 loss: 0.005140417255461216\n",
      "step 60 loss: 0.03348114341497421\n",
      "\n",
      "accuracy: 0.834\t auroc:0.8999594498699016\n",
      "use time: 11.703576803207397\n",
      "----------------------------------------\n",
      "epoch: 419\n",
      "step 0 loss: 0.02823984995484352\n",
      "step 20 loss: 0.03028213232755661\n",
      "step 40 loss: 0.05769466608762741\n",
      "step 60 loss: 0.019929300993680954\n",
      "\n",
      "accuracy: 0.843\t auroc:0.902484178208167\n",
      "use time: 11.645352840423584\n",
      "----------------------------------------\n",
      "epoch: 420\n",
      "step 0 loss: 0.014266947284340858\n",
      "step 20 loss: 0.03236891329288483\n",
      "step 40 loss: 0.010519405826926231\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "version = \"v9b2-davisbin-\"\n",
    "\n",
    "writer = SummaryWriter(tensorboard_path)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    print(\"--\"*20)\n",
    "    print(\"epoch: \" + str(epoch))\n",
    "    time0 = time.time()\n",
    "\n",
    "    avgloss = train_loop(model, trainDataLoader, loss_fn, optimizer, scheduler)\n",
    "    auroc, acc = test_loop(model, val_mol, val_seq, val_classify, writer, epoch)\n",
    "\n",
    "    writer.add_scalar(\"test time\", time.time()-time0, epoch)\n",
    "    writer.add_scalar('avgloss', avgloss , epoch)\n",
    "    writer.add_scalar('auroc', auroc , epoch)\n",
    "    writer.add_scalar('accuracy', acc , epoch)\n",
    "    writer.add_scalar('current lr', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "    print()\n",
    "    print(\"accuracy: \" + str(acc) + \"\\t auroc:\" + str(auroc))\n",
    "    print(\"use time: \" + str(time.time() - time0))\n",
    "    \n",
    "    model.eval()\n",
    "    if epoch % 50 == 0:\n",
    "        torch.save({'state_dict': model.state_dict()}, data_path + 'model/' + str(version) + \"e\" + str(epoch) + '.pth.tar')\n",
    "    else:\n",
    "        torch.save({'state_dict': model.state_dict()}, data_path + \"model/quicksave.pth.tar\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f923ce3d9a6c852fa4277c7633c15be33e3c2fd747753029b4f9b6323264f49d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
