{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "molembed_path = \"/home/wbm001/deeplpi/data/davis/mol.csv\"\n",
    "seqembed_path = \"/home/wbm001/deeplpi/data/davis/seq_6165.csv\"\n",
    "train_path = \"/home/wbm001/deeplpi/data/davis/trainset.csv\"\n",
    "test_path = \"/home/wbm001/deeplpi/data/davis/testset.csv\"\n",
    "tensorboard_path = \"/home/wbm001/deeplpi/DeepLPI/output/tensorboard/\"\n",
    "data_path = \"/home/wbm001/deeplpi/DeepLPI/output/\"\n",
    "\n",
    "RAMDOMSEED = 11\n",
    "CLASSIFYBOUND = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seqembed = pd.read_csv(seqembed_path)\n",
    "molembed = pd.read_csv(molembed_path)\n",
    "train = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.534e+04, 1.520e+03, 1.157e+03, 7.100e+02, 4.640e+02, 2.810e+02,\n",
       "        1.470e+02, 6.800e+01, 2.400e+01, 4.000e+00]),\n",
       " array([-4.        , -3.43802112, -2.87604225, -2.31406337, -1.7520845 ,\n",
       "        -1.19010562, -0.62812675, -0.06614787,  0.49583101,  1.05780988,\n",
       "         1.61978876]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(train[\"pKd (nM)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqembed = seqembed.set_index(\"id\").iloc[:,1:]\n",
    "molembed = molembed.set_index(\"id\").iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader,TensorDataset,SequentialSampler,RandomSampler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(train, test_size=1000, random_state=RAMDOMSEED)\n",
    "\n",
    "# train\n",
    "train_seq = tensor(np.array(seqembed.loc[train[\"seq\"]])).to(torch.float32)\n",
    "train_mol = tensor(np.array(molembed.loc[train[\"mol\"]])).to(torch.float32)\n",
    "train_classify = tensor(np.array(train[\"pKd (nM)\"])).to(torch.float32)\n",
    "\n",
    "trainDataset = TensorDataset(train_mol,train_seq,train_classify)\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=64)\n",
    "\n",
    "#val\n",
    "val_seq = tensor(np.array(seqembed.loc[val[\"seq\"]])).to(torch.float32)\n",
    "val_mol = tensor(np.array(molembed.loc[val[\"mol\"]])).to(torch.float32)\n",
    "val_classify = tensor(np.array(val[\"pKd (nM)\"])).to(torch.float32)\n",
    "\n",
    "# valDataset = TensorDataset(val_mol,val_seq,val_classify)\n",
    "# valDataLoader = DataLoader(valDataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_conv1=False, strides=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.process = nn.Sequential (\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=strides, padding=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_channels)\n",
    "        )\n",
    "        \n",
    "        if use_conv1:\n",
    "            self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv1 = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        left = self.process(x)\n",
    "        right = x if self.conv1 is None else self.conv1(x)\n",
    "        \n",
    "        return F.relu(left + right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnnModule(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, hidden_channel=32, dropout=0.3, headpooling=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head = nn.Sequential (\n",
    "            nn.Conv1d(in_channel, hidden_channel, 7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm1d(hidden_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.MaxPool1d(5, stride=3) if headpooling == True else nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        self.cnn = nn.Sequential (\n",
    "            resBlock(hidden_channel, out_channel, use_conv1=True, strides=1),\n",
    "            resBlock(out_channel, out_channel, strides=1),\n",
    "            resBlock(out_channel, out_channel, strides=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.head(x)\n",
    "        x = self.cnn(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLPI(nn.Module):\n",
    "    def __init__(self, molshape, seqshape, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.molshape = molshape\n",
    "        self.seqshape = seqshape\n",
    "\n",
    "        self.molcnn = cnnModule(1, 16, dropout=dropout)\n",
    "        self.seqcnn = cnnModule(1, 16, dropout=dropout, headpooling=True)\n",
    "        \n",
    "        self.pool = nn.AvgPool1d(7, stride = 5, padding=2)\n",
    "        self.lstm = nn.LSTM(16, 16, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.mlp = nn.Sequential (\n",
    "            nn.Linear(round(self.molshape/4+self.seqshape/30) * 16 * 2, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            nn.Linear(1024, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, mol, seq):\n",
    "        mol = self.molcnn(mol.reshape(-1,1,self.molshape))\n",
    "        seq = self.seqcnn(seq.reshape(-1,1,self.seqshape))\n",
    "        \n",
    "        # put data into lstm\n",
    "        seq = self.pool(seq)\n",
    "        # print(mol.shape,seq.shape)\n",
    "        x = torch.cat((mol,seq),2)\n",
    "        # print(mol.shape)\n",
    "        x = x.reshape(-1,round(self.molshape/4+self.seqshape/30),16)\n",
    "\n",
    "        x,_ = self.lstm(x)\n",
    "        # fully connect layer\n",
    "        # print(x.shape)\n",
    "        x = self.mlp(x.flatten(1))\n",
    "        \n",
    "        x = x.flatten()\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepLPI(300,6165)\n",
    "model(torch.randn(512,300),torch.randn(512,6165)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_dataloader, lossfunc, optimizer, scheduler):\n",
    "    model = model.to(\"cuda\")\n",
    "    model.train()\n",
    "    loop_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        step_mol, step_seq, step_label = batch\n",
    "        step_mol, step_seq, step_label = step_mol.to(\"cuda\"), step_seq.to(\"cuda\"), step_label.to(\"cuda\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(step_mol, step_seq)\n",
    "        loss = lossfunc(logits, step_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loop_loss += float(loss.to(\"cpu\"))\n",
    "\n",
    "        if step%20 == 0:\n",
    "            print(\"step \" + str(step) + \" loss: \" + str(float(loss.to(\"cpu\"))))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        return loop_loss/len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "def test_loop(model, val_mol, val_seq, val_lab, writer, epoch):\n",
    "    model.eval()\n",
    "    model = model.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        step_mol, step_seq = val_mol.to(\"cuda\"), val_seq.to(\"cuda\")\n",
    "        logits = model(step_mol,step_seq)\n",
    "    logits = logits.to(\"cpu\")\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.xlabel(\"true value\")\n",
    "    plt.ylabel(\"predict value\")\n",
    "    plt.scatter(logits, val_lab, alpha = 0.2, color='Black')\n",
    "    plt.plot(range(-9,4), range(-9,4),color=\"r\",linewidth=2)\n",
    "    plt.xlim(-9,4)\n",
    "    plt.ylim(-9,4)\n",
    "    writer.add_figure(tag='test evaluate', figure=fig, global_step=epoch)\n",
    "\n",
    "    return mean_squared_error(val_lab,logits), r2_score(val_lab,logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DeepLPI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a0fd2103dd7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepLPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6165\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitialize_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DeepLPI' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = DeepLPI(300,6165,dropout=0.2)\n",
    "\n",
    "model.apply(initialize_weights)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.8, min_lr=0.00001)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "writer = SummaryWriter(tensorboard_path)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    print(\"--\"*20)\n",
    "    print(\"epoch: \" + str(epoch))\n",
    "    time0 = time.time()\n",
    "\n",
    "    avgloss = train_loop(model, trainDataLoader, loss_fn, optimizer, scheduler)\n",
    "    msescore, r2score = test_loop(model, val_mol, val_seq, val_classify, writer, epoch)\n",
    "\n",
    "    writer.add_scalar(\"test time\", time.time()-time0, epoch)\n",
    "    writer.add_scalar('avgloss', avgloss , epoch)\n",
    "    writer.add_scalar('mse', msescore , epoch)\n",
    "    writer.add_scalar('r2', r2score , epoch)\n",
    "    writer.add_scalar('current lr', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "    print()\n",
    "    print(\"R2: \" + str(r2score) + \"\\t MSE: \" + str(msescore))\n",
    "    print(\"use time: \" + str(time.time() - time0))\n",
    "    \n",
    "    model.eval()\n",
    "    if epoch % 50 == 0:\n",
    "        torch.save({'state_dict': model.state_dict()}, data_path + 'model/' + str(version) + \"e\" + str(epoch) + '.pth.tar')\n",
    "    else:\n",
    "        torch.save({'state_dict': model.state_dict()}, data_path + \"model/quicksave.pth.tar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "epoch: 0\n",
      "step 0 loss: 20.074729919433594\n",
      "step 20 loss: 6.435692310333252\n",
      "step 40 loss: 3.4199204444885254\n",
      "step 60 loss: 2.150752067565918\n",
      "\n",
      "R2: -0.44635666295064036\t MSE: 0.88837296\n",
      "use time: 14.252944707870483\n",
      "----------------------------------------\n",
      "epoch: 1\n",
      "step 0 loss: 1.9945251941680908\n",
      "step 20 loss: 1.095957636833191\n",
      "step 40 loss: 1.2252490520477295\n",
      "step 60 loss: 0.9822773337364197\n",
      "\n",
      "R2: -0.19159300841212246\t MSE: 0.7318935\n",
      "use time: 11.240354776382446\n",
      "----------------------------------------\n",
      "epoch: 2\n",
      "step 0 loss: 0.9789406657218933\n",
      "step 20 loss: 0.9517605304718018\n",
      "step 40 loss: 0.8519464135169983\n",
      "step 60 loss: 0.8187798261642456\n",
      "\n",
      "R2: -0.05488035280685599\t MSE: 0.64792264\n",
      "use time: 11.275174856185913\n",
      "----------------------------------------\n",
      "epoch: 3\n",
      "step 0 loss: 0.7700061798095703\n",
      "step 20 loss: 0.9832063913345337\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cf7ff7ae22de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtime0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mavgloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmsescore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_classify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-bfc11eee6127>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, train_dataloader, lossfunc, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_mol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloop_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wbm001/miniconda3/envs/DeepPurpose/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wbm001/miniconda3/envs/DeepPurpose/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = DeepLPI(300,6165,dropout=0.2)\n",
    "\n",
    "model.apply(initialize_weights)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.8, min_lr=0.00001)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "writer = SummaryWriter(tensorboard_path)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    print(\"--\"*20)\n",
    "    print(\"epoch: \" + str(epoch))\n",
    "    time0 = time.time()\n",
    "\n",
    "    avgloss = train_loop(model, trainDataLoader, loss_fn, optimizer, scheduler)\n",
    "    msescore, r2score = test_loop(model, val_mol, val_seq, val_classify, writer, epoch)\n",
    "\n",
    "    writer.add_scalar(\"test time\", time.time()-time0, epoch)\n",
    "    writer.add_scalar('avgloss', avgloss , epoch)\n",
    "    writer.add_scalar('mse', msescore , epoch)\n",
    "    writer.add_scalar('r2', r2score , epoch)\n",
    "    writer.add_scalar('current lr', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "    print()\n",
    "    print(\"R2: \" + str(r2score) + \"\\t MSE: \" + str(msescore))\n",
    "    print(\"use time: \" + str(time.time() - time0))\n",
    "    \n",
    "    model.eval()\n",
    "    if epoch % 50 == 0:\n",
    "        torch.save({'state_dict': model.state_dict()}, data_path + 'model/' + str(version) + \"e\" + str(epoch) + '.pth.tar')\n",
    "    else:\n",
    "        torch.save({'state_dict': model.state_dict()}, data_path + \"model/quicksave.pth.tar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('DeepPurpose')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f923ce3d9a6c852fa4277c7633c15be33e3c2fd747753029b4f9b6323264f49d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
